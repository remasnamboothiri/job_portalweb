{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Interview - {{ interview.job_position.title|default:"Job Position" }}</title>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ðŸ¤–</text></svg>">

    <style>
        * {
            margin: 0 !important;
            padding: 0 !important;
            box-sizing: border-box;
        }
        
        body {
            margin: 0 !important;
            padding: 0 !important;
            background: #202124 !important;
            color: white !important;
            font-family: 'Google Sans', sans-serif !important;
            overflow: hidden !important;
            width: 100vw !important;
            height: 100vh !important;
        }
        
        html {
            width: 100% !important;
            height: 100% !important;
            margin: 0 !important;
            padding: 0 !important;
        }
        
        .interview-progress {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            height: 4px;
            background: rgba(255,255,255,0.1);
            z-index: 1000;
        }
        
        .interview-progress-bar {
            height: 100%;
            background: #34a853;
            transition: width 0.3s ease;
        }
        
        .interview-stats {
            position: fixed;
            top: 20px;
            right: 20px;
            display: flex;
            gap: 20px;
            z-index: 1000;
        }
        
        .stat-item {
            background: rgba(0,0,0,0.8);
            padding: 8px 16px;
            border-radius: 20px;
            text-align: center;
        }
        
        .stat-value {
            font-size: 18px;
            font-weight: bold;
            color: #34a853;
        }
        
        .stat-label {
            font-size: 12px;
            color: #9aa0a6;
        }
        
        .meet-container {
            height: 100vh;
            display: flex;
            flex-direction: column;
            background: #202124;
        }
        
        .video-grid {
            flex: 1;
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 16px;
            padding: 20px;
            max-height: 70vh;
        }
        
        .video-participant {
            background: #303134;
            border-radius: 12px;
            position: relative;
            display: flex;
            align-items: center;
            justify-content: center;
            min-height: 300px;
        }
        
        .ai-avatar {
            font-size: 80px;
            animation: pulse 2s infinite;
        }
        
        .participant-video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            border-radius: 12px;
        }
        
        .participant-name {
            position: absolute;
            bottom: 16px;
            left: 16px;
            background: rgba(0,0,0,0.8);
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 14px;
        }
        
        .subtitle-overlay {
            position: fixed;
            bottom: 150px;
            left: 50%;
            transform: translateX(-50%);
            max-width: 80%;
            background: rgba(0,0,0,0.9);
            padding: 20px;
            border-radius: 12px;
            text-align: center;
            opacity: 0;
            transition: opacity 0.3s ease;
        }
        
        .subtitle-overlay.show {
            opacity: 1;
        }
        
        .subtitle-text {
            font-size: 16px;
            line-height: 1.4;
        }
        
        .meet-controls {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 16px;
            z-index: 1000;
        }
        
        .control-btn {
            width: 56px;
            height: 56px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 24px;
            transition: all 0.3s ease;
            background: #5f6368;
            color: white;
        }
        
        .control-btn.mic-active {
            background: #34a853;
        }
        
        .control-btn.mic-muted {
            background: #ea4335;
        }
        
        .end-btn {
            background: #ea4335;
        }
        
        .control-btn:hover {
            transform: scale(1.1);
        }
        
        .completion-modal {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0,0,0,0.9);
            display: none;
            align-items: center;
            justify-content: center;
            z-index: 2000;
        }
        
        .completion-modal.show {
            display: flex;
        }
        
        .modal-content {
            background: #303134;
            padding: 40px;
            border-radius: 16px;
            text-align: center;
            max-width: 500px;
        }
        
        .btn-primary {
            background: #1a73e8;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            margin: 10px;
        }
        
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }
        
        @media (max-width: 768px) {
            .video-grid {
                grid-template-columns: 1fr;
                padding: 10px;
            }
            
            .interview-stats {
                top: 10px;
                right: 10px;
                gap: 10px;
            }
            
            .stat-item {
                padding: 6px 12px;
            }
            
            .stat-value {
                font-size: 16px;
            }
        }
        
        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
    </style>
</head>
<body>
    <!-- Interview Progress Bar -->
    <div class="interview-progress">
        <div class="interview-progress-bar" id="progressBar" style="width: 12.5%;"></div>
    </div>

    <!-- Interview Stats -->
    <div class="interview-stats">
        <div class="stat-item">
            <div class="stat-value" id="questionCounter">1/8</div>
            <div class="stat-label">Questions</div>
        </div>
        <div class="stat-item">
            <div class="stat-value" id="timer">15:00</div>
            <div class="stat-label">Time Left</div>
        </div>
    </div>

    <!-- Main Interview Container -->
    <div class="meet-container">
        <!-- Video Grid -->
        <div class="video-grid">
            <!-- AI Interviewer -->
            <div class="video-participant ai-interviewer">
                <div class="ai-avatar" id="aiAvatar">ðŸ¤–</div>
                <div class="participant-name">Alex - AI Interviewer</div>
            </div>

            <!-- User Video -->
            <div class="video-participant candidate">
                <video class="participant-video" id="userVideo" autoplay muted playsinline></video>
                <div class="participant-name">{{ candidate_name|default:"You" }}</div>
                <div id="recordingIndicator" style="position: absolute; top: 10px; left: 10px; background: #ea4335; color: white; padding: 4px 8px; border-radius: 12px; font-size: 12px; display: none; align-items: center; gap: 4px;">
                    <span style="width: 8px; height: 8px; background: white; border-radius: 50%; animation: blink 1s infinite;"></span>
                    REC
                </div>
            </div>
        </div>

        <!-- Subtitle Overlay -->
        <div class="subtitle-overlay" id="subtitleOverlay">
            <div class="subtitle-text" id="subtitleText" data-initial-text="{{ ai_question|default:"Hello! Welcome to your AI interview. Can you tell me about yourself and why you're interested in this position?" }}">
                <!-- Text will be populated by typewriter effect -->
            </div>
        </div>

        <!-- Meet Controls -->
        <div class="meet-controls">
            <button class="control-btn mic-active" id="muteBtn" title="Mute/Unmute">ðŸŽ¤</button>
            <button class="control-btn" id="cameraBtn" title="Camera">ðŸ“¹</button>
            <button class="control-btn end-btn" id="endBtn" title="End interview">ðŸ“ž</button>
        </div>
    </div>

    <!-- Completion Modal -->
    <div class="completion-modal" id="completionModal">
        <div class="modal-content">
            <h3>Interview Complete! ðŸŽ‰</h3>
            <p>Thank you for taking the time to interview with us. We'll review your responses and get back to you within 2-3 business days.</p>
            <button class="btn-primary" onclick="window.location.href='{% url 'jobseeker_dashboard' %}'">
                Back to Dashboard
            </button>
        </div>
    </div>

    <!-- Audio Elements -->
    <audio id="aiAudioPlayer" style="display: none;"></audio>
    
    <!-- Interview Microphone Always-On System -->
    <script src="{% static 'js/interview-microphone-always-on.js' %}"></script>
    
    <!-- Typewriter Synchronization System -->
    <script src="{% static 'js/typewriter-sync.js' %}"></script>

    <!-- CSRF Token -->
    {% csrf_token %}

    <script>
        // Global variables
        let isMicOn = true;
        let currentQuestionCount = 1;
        let interviewTimer = null;
        let startTime = new Date();
        let totalTimeMinutes = 15; // 15 minutes total
        
        // Get CSRF token
        function getCSRFToken() {
            return document.querySelector('[name=csrfmiddlewaretoken]').value;
        }

        // Camera and Recording Variables
        let mediaRecorder = null;
        let recordedChunks = [];
        let isRecording = false;
        let isCameraOn = true;
        let userStream = null;

        // Initialize camera with recording
        async function initializeCamera() {
            try {
                userStream = await navigator.mediaDevices.getUserMedia({
                    video: { width: { ideal: 1280 }, height: { ideal: 720 } },
                    audio: true
                });
                
                const userVideo = document.getElementById('userVideo');
                userVideo.srcObject = userStream;
                console.log('Camera initialized successfully');
                
                // Setup recording
                setupRecording();
                
                // Setup camera button
                setupCameraButton();
                
            } catch (error) {
                console.error('Camera initialization failed:', error);
            }
        }
        
        // Setup recording
        function setupRecording() {
            if (!userStream) return;
            
            try {
                mediaRecorder = new MediaRecorder(userStream, {
                    mimeType: 'video/webm'
                });
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    saveRecording();
                };
                
                // Auto-start recording
                setTimeout(() => {
                    startRecording();
                }, 2000);
                
            } catch (error) {
                console.error('Recording setup failed:', error);
            }
        }
        
        // Start recording
        function startRecording() {
            if (mediaRecorder && !isRecording) {
                recordedChunks = [];
                mediaRecorder.start(1000);
                isRecording = true;
                
                const indicator = document.getElementById('recordingIndicator');
                if (indicator) {
                    indicator.style.display = 'flex';
                }
                
                console.log('Recording started');
            }
        }
        
        // Stop recording
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                
                const indicator = document.getElementById('recordingIndicator');
                if (indicator) {
                    indicator.style.display = 'none';
                }
                
                console.log('Recording stopped');
            }
        }
        
        // Save recording
        async function saveRecording() {
            if (recordedChunks.length === 0) return;
            
            try {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const formData = new FormData();
                
                const pathParts = window.location.pathname.split('/');
                const uuid = pathParts[pathParts.length - 2];
                
                formData.append('recording', blob, `interview-${uuid}.webm`);
                formData.append('interview_uuid', uuid);
                formData.append('duration', '300');
                
                const csrfToken = getCSRFToken();
                
                const response = await fetch('/save-interview-recording/', {
                    method: 'POST',
                    headers: { 'X-CSRFToken': csrfToken },
                    body: formData
                });
                
                if (response.ok) {
                    console.log('Recording saved successfully');
                } else {
                    console.error('Failed to save recording');
                }
                
            } catch (error) {
                console.error('Error saving recording:', error);
            }
        }
        
        // Setup camera button
        function setupCameraButton() {
            const cameraBtn = document.getElementById('cameraBtn');
            if (!cameraBtn) return;
            
            cameraBtn.onclick = function() {
                toggleCamera();
            };
            
            updateCameraButton();
        }
        
        // Toggle camera
        function toggleCamera() {
            if (!userStream) return;
            
            const videoTracks = userStream.getVideoTracks();
            isCameraOn = !isCameraOn;
            
            videoTracks.forEach(track => {
                track.enabled = isCameraOn;
            });
            
            updateCameraButton();
            console.log(`Camera ${isCameraOn ? 'ON' : 'OFF'}`);
        }
        
        // Update camera button
        function updateCameraButton() {
            const cameraBtn = document.getElementById('cameraBtn');
            if (!cameraBtn) return;
            
            if (isCameraOn) {
                cameraBtn.style.background = '#5f6368';
                cameraBtn.title = 'Turn off camera';
            } else {
                cameraBtn.style.background = '#ea4335';
                cameraBtn.title = 'Turn on camera';
            }
        }

        // Update timer display
        function updateTimer() {
            const elapsedSeconds = Math.floor((new Date() - startTime) / 1000);
            const totalSeconds = totalTimeMinutes * 60;
            const remainingSeconds = Math.max(0, totalSeconds - elapsedSeconds);
            
            const minutes = Math.floor(remainingSeconds / 60);
            const seconds = remainingSeconds % 60;
            
            document.getElementById('timer').textContent = `${minutes}:${seconds.toString().padStart(2, '0')}`;
            
            if (remainingSeconds <= 0) {
                clearInterval(interviewTimer);
                showCompletionModal();
            }
        }

        // Start timer
        function startTimer() {
            interviewTimer = setInterval(updateTimer, 1000);
        }

        // Toggle microphone (but keep it always on for interview)
        function toggleMicrophone() {
            // In interview mode, microphone should always stay on
            // Only toggle speech recognition
            if (isMicOn) {
                // Stop speech recognition but keep mic on
                speechRecognitionBlocked = true;
                stopSpeechRecognition();
                
                const muteBtn = document.getElementById('muteBtn');
                muteBtn.classList.remove('mic-active');
                muteBtn.classList.add('mic-muted');
                muteBtn.innerHTML = 'ðŸ”‡';
                muteBtn.title = 'Speech recognition disabled - Click to enable';
                
                console.log('ðŸ”‡ Speech recognition disabled (mic hardware stays on)');
            } else {
                // Re-enable speech recognition
                speechRecognitionBlocked = false;
                
                const muteBtn = document.getElementById('muteBtn');
                muteBtn.classList.add('mic-active');
                muteBtn.classList.remove('mic-muted');
                muteBtn.innerHTML = 'ðŸŽ¤';
                muteBtn.title = 'Speech recognition enabled - Always listening';
                
                // Start speech recognition if not blocked by AI
                if (!isAISpeaking) {
                    startSpeechRecognition();
                }
                
                console.log('ðŸŽ¤ Speech recognition enabled');
            }
            
            // Note: We don't actually disable the microphone hardware
            // The microphone stays on for the entire interview
            // We only control speech recognition
        }

        // Show completion modal
        function showCompletionModal() {
            // Stop recording before showing modal
            stopRecording();
            
            setTimeout(() => {
                document.getElementById('completionModal').classList.add('show');
            }, 1000);
        }

        // Legacy typewriter function for compatibility
        function typewriterEffect(element, text, duration, callback) {
            if (window.TypewriterSync) {
                window.TypewriterSync.createNatural(element, text, duration)
                    .then(() => {
                        if (callback) callback();
                    });
            } else {
                // Fallback implementation
                element.textContent = '';
                let index = 0;
                const totalChars = text.length;
                const effectiveDuration = duration ? duration * 1000 : Math.max(text.length * 80, 2000);
                const charDelay = effectiveDuration / totalChars;
                
                function typeChar() {
                    if (index < totalChars) {
                        element.textContent += text.charAt(index);
                        index++;
                        setTimeout(typeChar, charDelay);
                    } else if (callback) {
                        callback();
                    }
                }
                typeChar();
            }
        }
        
        // Enhanced synchronized typewriter using new system
        function synchronizedTypewriter(element, text, audioElement, callback) {
            if (window.TypewriterSync) {
                window.TypewriterSync.createSynchronized(element, text, audioElement)
                    .then(() => {
                        if (callback) callback();
                    });
            } else {
                // Fallback to regular typewriter
                typewriterEffect(element, text, null, callback);
            }
        }
        
        // Handle AI response with improved typewriter sync
        function handleAIResponse(data) {
            // Update question counter
            currentQuestionCount = data.question_count || currentQuestionCount + 1;
            document.getElementById('questionCounter').textContent = `${currentQuestionCount}/8`;
            
            // Update progress bar
            const progress = (currentQuestionCount / 8) * 100;
            document.getElementById('progressBar').style.width = `${progress}%`;
            
            // Block speech recognition while AI is speaking
            isAISpeaking = true;
            speechRecognitionBlocked = true;
            stopSpeechRecognition();
            
            console.log('ðŸ¤– AI is speaking - speech recognition blocked');
            
            // Show subtitle overlay
            const subtitleOverlay = document.getElementById('subtitleOverlay');
            subtitleOverlay.classList.add('show');
            
            // Start synchronized typewriter and audio
            if (data.audio && data.audio.trim() !== '') {
                playAIAudioWithSyncedTypewriter(data.audio, data.response, data.audio_duration);
            } else {
                // No audio, use natural typewriter timing
                const subtitleText = document.getElementById('subtitleText');
                typewriterEffect(subtitleText, data.response, null, () => {
                    setTimeout(() => {
                        handleAIFinishedSpeaking();
                    }, 1000);
                });
            }
            
            // Hide subtitles after appropriate time
            const hideDelay = data.audio_duration ? (data.audio_duration * 1000) + 3000 : 8000;
            setTimeout(() => {
                subtitleOverlay.classList.remove('show');
            }, hideDelay);
            
            // Check if interview is complete
            if (data.is_final || currentQuestionCount >= 8) {
                setTimeout(showCompletionModal, 2000);
            }
        }
        
        // Handle when AI finishes speaking
        function handleAIFinishedSpeaking() {
            isAISpeaking = false;
            
            // Wait a moment before re-enabling speech recognition
            setTimeout(() => {
                if (isMicOn && !speechRecognitionBlocked) {
                    speechRecognitionBlocked = false;
                    startSpeechRecognition();
                    console.log('ðŸŽ¤ AI finished speaking - speech recognition re-enabled');
                }
            }, 1000); // 1 second delay to ensure AI audio has fully stopped
        }
        
        // Play AI audio with perfectly synced typewriter effect - COMPLETELY FIXED VERSION
        function playAIAudioWithSyncedTypewriter(audioUrl, text, audioDuration) {
            const audioPlayer = document.getElementById('aiAudioPlayer');
            const subtitleText = document.getElementById('subtitleText');
            
            // CRITICAL FIX: Clear text first and ensure it stays empty until audio ACTUALLY starts
            subtitleText.textContent = '';
            
            if (audioUrl && audioUrl.trim() !== '') {
                console.log(`ðŸ”Š COMPLETELY FIXED: Starting synchronized audio and typewriter`);
                console.log(`ðŸ”Š Audio URL: ${audioUrl}`);
                console.log(`ðŸ”Š Text length: ${text.length} characters`);
                console.log(`ðŸ”Š Audio duration: ${audioDuration} seconds`);
                
                // Set audio source
                audioPlayer.src = audioUrl;
                
                // CRITICAL FIX: Wait for audio to be completely ready AND playing before starting typewriter
                let audioStarted = false;
                let typewriterStarted = false;
                
                const startTypewriterWhenReady = () => {
                    if (audioStarted && !typewriterStarted) {
                        typewriterStarted = true;
                        console.log('ðŸ”Š COMPLETELY FIXED: Audio confirmed playing, NOW starting typewriter');
                        
                        // Start typewriter synchronized with playing audio
                        if (window.TypewriterSync) {
                            window.TypewriterSync.createSynchronized(subtitleText, text, audioPlayer)
                                .then(() => {
                                    console.log('ðŸ–Šï¸ COMPLETELY FIXED: Synchronized typewriter completed');
                                });
                        } else {
                            // Fallback to legacy synchronized typewriter
                            synchronizedTypewriter(subtitleText, text, audioPlayer, () => {
                                console.log('ðŸ–Šï¸ COMPLETELY FIXED: Legacy typewriter completed');
                            });
                        }
                    }
                };
                
                // Wait for audio to be ready to play
                audioPlayer.oncanplaythrough = () => {
                    console.log('ðŸ”Š COMPLETELY FIXED: Audio loaded and ready');
                    
                    // Start audio playback
                    audioPlayer.play().then(() => {
                        console.log('ðŸ”Š COMPLETELY FIXED: Audio play() promise resolved');
                        // Don't start typewriter yet - wait for actual playback confirmation
                    }).catch(error => {
                        console.error('COMPLETELY FIXED: Audio play failed:', error);
                        // Fall back to natural typewriter with estimated duration
                        const estimatedDuration = audioDuration || (window.TypewriterSync ? window.TypewriterSync.estimateDuration(text) : 5);
                        if (window.TypewriterSync) {
                            window.TypewriterSync.createNatural(subtitleText, text, estimatedDuration)
                                .then(() => handleAIFinishedSpeaking());
                        } else {
                            typewriterEffect(subtitleText, text, estimatedDuration, () => {
                                handleAIFinishedSpeaking();
                            });
                        }
                    });
                };
                
                // CRITICAL: Wait for actual audio playback to start (not just play() promise)
                audioPlayer.onplaying = () => {
                    console.log('ðŸ”Š COMPLETELY FIXED: Audio is ACTUALLY playing now!');
                    audioStarted = true;
                    // Small delay to ensure audio is truly playing
                    setTimeout(startTypewriterWhenReady, 100);
                };
                
                audioPlayer.ontimeupdate = () => {
                    // Ensure typewriter starts even if onplaying doesn't fire
                    if (audioPlayer.currentTime > 0.1 && !audioStarted) {
                        console.log('ðŸ”Š COMPLETELY FIXED: Audio confirmed via timeupdate');
                        audioStarted = true;
                        startTypewriterWhenReady();
                    }
                };
                
                audioPlayer.onended = () => {
                    console.log('ðŸ”Š COMPLETELY FIXED: AI audio finished playing');
                    handleAIFinishedSpeaking();
                };
                
                audioPlayer.onerror = (error) => {
                    console.error('COMPLETELY FIXED: Audio playback error:', error);
                    // Fall back to natural typewriter with estimated duration
                    const estimatedDuration = audioDuration || (window.TypewriterSync ? window.TypewriterSync.estimateDuration(text) : 5);
                    if (window.TypewriterSync) {
                        window.TypewriterSync.createNatural(subtitleText, text, estimatedDuration)
                            .then(() => handleAIFinishedSpeaking());
                    } else {
                        typewriterEffect(subtitleText, text, estimatedDuration, () => {
                            handleAIFinishedSpeaking();
                        });
                    }
                };
                
                // Timeout fallback in case audio never starts
                setTimeout(() => {
                    if (!audioStarted) {
                        console.log('ðŸ”Š COMPLETELY FIXED: Audio timeout, starting typewriter anyway');
                        audioStarted = true;
                        startTypewriterWhenReady();
                    }
                }, 3000); // 3 second timeout
                
                // Load the audio - this triggers the oncanplaythrough event
                audioPlayer.load();
                
            } else {
                console.log('ðŸ–Šï¸ COMPLETELY FIXED: No audio, using natural typewriter timing');
                // No audio, use natural typewriter with estimated duration
                const estimatedDuration = audioDuration || (window.TypewriterSync ? window.TypewriterSync.estimateDuration(text) : 5);
                if (window.TypewriterSync) {
                    window.TypewriterSync.createNatural(subtitleText, text, estimatedDuration)
                        .then(() => handleAIFinishedSpeaking());
                } else {
                    typewriterEffect(subtitleText, text, estimatedDuration, () => {
                        handleAIFinishedSpeaking();
                    });
                }
            }
        }
        
        // Legacy function for compatibility
        function playAIAudio(audioUrl) {
            const audioPlayer = document.getElementById('aiAudioPlayer');
            
            if (audioUrl && audioUrl.trim() !== '') {
                audioPlayer.src = audioUrl;
                
                audioPlayer.onended = () => {
                    console.log('ðŸ”Š AI audio finished playing');
                    handleAIFinishedSpeaking();
                };
                
                audioPlayer.onerror = (error) => {
                    console.error('Audio playback error:', error);
                    handleAIFinishedSpeaking();
                };
                
                audioPlayer.play().catch(error => {
                    console.error('Audio play failed:', error);
                    handleAIFinishedSpeaking();
                });
            } else {
                handleAIFinishedSpeaking();
            }
        }

        // Send response to backend
        async function sendResponse(text) {
            try {
                const response = await fetch(window.location.href, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/x-www-form-urlencoded',
                        'X-CSRFToken': getCSRFToken(),
                    },
                    body: new URLSearchParams({ text: text })
                });
                
                const data = await response.json();
                
                if (data.success) {
                    handleAIResponse(data);
                }
            } catch (error) {
                console.error('Error sending response:', error);
            }
        }

        // Speech recognition variables
        let recognition = null;
        let isListening = false;
        let isAISpeaking = false;
        let speechRecognitionBlocked = false;
        
        // Initialize speech recognition
        function initializeSpeechRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                
                recognition.lang = 'en-US';
                recognition.interimResults = false;
                recognition.continuous = true;
                recognition.maxAlternatives = 1;
                
                recognition.onstart = function() {
                    console.log('ðŸŽ¤ Speech recognition started');
                    isListening = true;
                };
                
                recognition.onend = function() {
                    console.log('ðŸŽ¤ Speech recognition ended');
                    isListening = false;
                    
                    // Auto-restart if not blocked and mic is on
                    if (isMicOn && !speechRecognitionBlocked && !isAISpeaking) {
                        setTimeout(() => {
                            if (isMicOn && !speechRecognitionBlocked && !isAISpeaking) {
                                startSpeechRecognition();
                            }
                        }, 500);
                    }
                };
                
                recognition.onresult = function(event) {
                    // Only process if not blocked by AI speech
                    if (!speechRecognitionBlocked && !isAISpeaking) {
                        const transcript = event.results[event.results.length - 1][0].transcript;
                        console.log('ðŸ—£ï¸ User said:', transcript);
                        sendResponse(transcript);
                    } else {
                        console.log('ðŸš« Speech recognition blocked - AI is speaking');
                    }
                };
                
                recognition.onerror = function(error) {
                    console.error('Speech recognition error:', error);
                    if (error.error === 'not-allowed') {
                        alert('Microphone permission denied. Please allow microphone access and refresh the page.');
                    }
                };
                
                // Start initial recognition
                if (isMicOn) {
                    startSpeechRecognition();
                }
            }
        }
        
        // Start speech recognition
        function startSpeechRecognition() {
            if (recognition && !isListening && isMicOn && !speechRecognitionBlocked && !isAISpeaking) {
                try {
                    recognition.start();
                } catch (e) {
                    console.log('Recognition already started or failed to start:', e);
                }
            }
        }
        
        // Stop speech recognition
        function stopSpeechRecognition() {
            if (recognition && isListening) {
                recognition.stop();
            }
        }
        
        // Event listeners
        document.addEventListener('DOMContentLoaded', async () => {
            // Initialize camera
            await initializeCamera();
            
            // Initialize speech recognition
            initializeSpeechRecognition();
            
            // Ensure microphone button shows correct initial state
            const muteBtn = document.getElementById('muteBtn');
            muteBtn.classList.add('mic-active');
            muteBtn.innerHTML = 'ðŸŽ¤';
            muteBtn.title = 'Speech recognition enabled - Always listening';
            
            // Start timer
            startTimer();
            
            // Show initial subtitle with synchronized typewriter effect
            setTimeout(() => {
                const subtitleOverlay = document.getElementById('subtitleOverlay');
                const subtitleText = document.getElementById('subtitleText');
                const initialText = subtitleText.getAttribute('data-initial-text') || subtitleText.textContent;
                
                subtitleOverlay.classList.add('show');
                
                // Clear text content for typewriter effect
                subtitleText.textContent = '';
                
                // Check if there's initial audio
                const initialAudio = `{{ audio_url|safe }}`;
                const serverDuration = {{ audio_duration|default:"null" }};
                
                if (initialAudio && initialAudio !== 'None' && initialAudio !== '' && initialAudio !== 'null') {
                    console.log('ðŸ”Š Setting up initial audio with synchronized typewriter');
                    
                    // Block speech recognition during initial question
                    isAISpeaking = true;
                    speechRecognitionBlocked = true;
                    
                    // Start synchronized audio and typewriter
                    playAIAudioWithSyncedTypewriter(initialAudio, initialText, serverDuration);
                } else {
                    console.log('ðŸ–Šï¸ No initial audio, using natural typewriter timing');
                    
                    // Block speech recognition during initial question
                    isAISpeaking = true;
                    speechRecognitionBlocked = true;
                    
                    // No audio, use natural typewriter timing
                    if (window.TypewriterSync) {
                        const estimatedDuration = window.TypewriterSync.estimateDuration(initialText);
                        window.TypewriterSync.createNatural(subtitleText, initialText, estimatedDuration)
                            .then(() => {
                                // Enable speech recognition after typewriter completes
                                setTimeout(() => {
                                    handleAIFinishedSpeaking();
                                }, 1000);
                            });
                    } else {
                        typewriterEffect(subtitleText, initialText, null, () => {
                            // Enable speech recognition after typewriter completes
                            setTimeout(() => {
                                handleAIFinishedSpeaking();
                            }, 1000);
                        });
                    }
                }
            }, 1000);
            
            // Hide initial subtitle after 10 seconds
            setTimeout(() => {
                document.getElementById('subtitleOverlay').classList.remove('show');
            }, 11000);
        });

        // Button event listeners
        document.getElementById('muteBtn').addEventListener('click', () => {
            // Toggle speech recognition state (not actual microphone)
            isMicOn = !isMicOn;
            toggleMicrophone();
        });
        
        document.getElementById('endBtn').addEventListener('click', () => {
            if (confirm('Are you sure you want to end the interview?')) {
                showCompletionModal();
            }
        });

        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            if (interviewTimer) {
                clearInterval(interviewTimer);
            }
        });
    </script>
</body>
</html>
    </script>
</body>
</html>


{% comment %} {% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="csrf-token" content="{{ csrf_token }}">
    <title>AI Interview - {{ interview.job.title|default:"Job Position" }}</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    
    <style>
        :root {
            --primary-color: #1a73e8;
            --secondary-color: #34a853;
            --danger-color: #ea4335;
            --warning-color: #fbbc04;
            --dark-bg: #202124;
            --card-bg: #303134;
            --text-light: #ffffff;
            --text-muted: #9aa0a6;
            --border-color: #5f6368;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Google Sans', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--dark-bg);
            color: var(--text-light);
            overflow: hidden;
            height: 100vh;
        }

        .interview-header {
            background: var(--card-bg);
            padding: 12px 24px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 1px solid var(--border-color);
            position: relative;
            z-index: 1000;
        }

        .interview-info {
            display: flex;
            align-items: center;
            gap: 16px;
        }

        .interview-title {
            font-size: 18px;
            font-weight: 500;
            color: var(--text-light);
        }

        .job-title {
            background: var(--primary-color);
            padding: 4px 12px;
            border-radius: 16px;
            font-size: 14px;
            color: white;
        }

        .interview-timer {
            display: flex;
            align-items: center;
            gap: 16px;
        }

        .timer-display {
            font-family: 'Courier New', monospace;
            font-size: 20px;
            font-weight: bold;
            color: var(--danger-color);
        }

        .question-counter {
            background: var(--secondary-color);
            color: white;
            padding: 6px 12px;
            border-radius: 20px;
            font-size: 14px;
            font-weight: 500;
        }

        .main-container {
            height: calc(100vh - 80px);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .video-container {
            flex: 0 0 auto;
            height: 40vh;
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 12px;
            padding: 16px;
            background: var(--dark-bg);
        }

        .video-participant {
            background: var(--card-bg);
            border-radius: 12px;
            position: relative;
            overflow: hidden;
            display: flex;
            align-items: center;
            justify-content: center;
            border: 2px solid transparent;
            transition: all 0.3s ease;
        }

        .video-participant.speaking {
            border-color: var(--secondary-color);
            box-shadow: 0 0 20px rgba(52, 168, 83, 0.3);
        }

        .ai-interviewer {
            background: linear-gradient(135deg, #010407ff, #2f2f2fff);
        }

        .candidate-video {
            background: linear-gradient(135deg, #061109ff, #404143ff);
        }

        .participant-avatar {
            width: 160px;
            height: 160px;
            border-radius: 50%;
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(10px);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 64px;
            color: white;
            border: 3px solid rgba(255, 255, 255, 0.3);
            transition: all 0.3s ease;
        }

        .participant-avatar.speaking {
            transform: scale(1.1);
            animation: pulse 1.5s infinite;
        }

        .participant-name {
            position: absolute;
            bottom: 16px;
            left: 16px;
            background: rgba(0, 0, 0, 0.8);
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 16px;
            font-weight: 500;
            color: white;
        }

        .participant-status {
            position: absolute;
            top: 16px;
            right: 16px;
            padding: 6px 12px;
            border-radius: 16px;
            font-size: 12px;
            font-weight: 500;
            display: none;
        }

        .status-speaking {
            background: var(--secondary-color);
            color: white;
            display: block;
        }

        .status-listening {
            background: var(--primary-color);
            color: white;
            display: block;
        }

        .recording-indicator {
            position: absolute;
            top: 16px;
            left: 16px;
            background: var(--danger-color);
            color: white;
            padding: 6px 12px;
            border-radius: 16px;
            font-size: 12px;
            font-weight: 500;
            display: none;
            align-items: center;
            gap: 6px;
        }

        .recording-indicator.active {
            display: flex;
            animation: blink 1s infinite;
        }

        .bottom-section {
            background: var(--card-bg);
            border-top: 1px solid var(--border-color);
            display: flex;
            flex-direction: column;
            flex: 1;
            min-height: 0;
        }

        .transcript-header {
            padding: 16px 24px;
            border-bottom: 1px solid var(--border-color);
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .transcript-title {
            font-size: 16px;
            font-weight: 500;
            color: var(--text-light);
        }

        .transcript-toggle {
            background: none;
            border: none;
            color: var(--primary-color);
            cursor: pointer;
            font-size: 14px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .transcript-content {
            flex: 1;
            overflow-y: auto;
            padding: 16px 24px;
            display: flex;
            flex-direction: column;
            gap: 12px;
            border: 1px solid var(--border-color);
            border-radius: 8px;
            background: var(--dark-bg);
            min-height: 200px;
        }

        .transcript-content.collapsed {
            height: 0;
            padding: 0;
            overflow: hidden;
        }

        .current-question {
            background: rgba(26, 115, 232, 0.1);
            border: 1px solid var(--primary-color);
            padding: 16px;
            border-radius: 8px;
            margin-bottom: 16px;
            position: relative;
        }
        
        .audio-status {
            position: absolute;
            top: 8px;
            right: 8px;
            padding: 4px 8px;
            border-radius: 12px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .audio-status.available {
            background: var(--secondary-color);
            color: white;
        }
        
        .audio-status.unavailable {
            background: var(--warning-color);
            color: var(--dark-bg);
        }
        
        .audio-status.error {
            background: var(--danger-color);
            color: white;
        }

        .current-question-title {
            font-size: 14px;
            color: var(--primary-color);
            font-weight: 500;
            margin-bottom: 8px;
        }

        .current-question-text {
            font-size: 15px;
            line-height: 1.4;
        }

        .transcript-message {
            display: flex;
            gap: 12px;
            margin-bottom: 16px;
            animation: slideIn 0.3s ease;
        }

        .message-avatar {
            width: 32px;
            height: 32px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 14px;
            flex-shrink: 0;
        }

        .transcript-message.interviewer .message-avatar {
            background: var(--primary-color);
            color: white;
        }

        .transcript-message.candidate .message-avatar {
            background: var(--secondary-color);
            color: white;
        }

        .message-content {
            flex: 1;
        }

        .message-header {
            display: flex;
            align-items: center;
            gap: 8px;
            margin-bottom: 4px;
        }

        .message-name {
            font-weight: 500;
            font-size: 14px;
        }

        .message-time {
            font-size: 12px;
            color: var(--text-muted);
        }

        .message-text {
            font-size: 15px;
            line-height: 1.4;
            color: var(--text-light);
        }

        .controls-bar {
            background: var(--dark-bg);
            padding: 20px;
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 20px;
            border-top: 1px solid var(--border-color);
            flex: 0 0 auto;
            position: sticky;
            bottom: 0;
            z-index: 100;
        }

        .control-btn {
            width: 56px;
            height: 56px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 24px;
            transition: all 0.3s ease;
            position: relative;
        }

        .mic-btn {
            background: var(--secondary-color);
            color: white;
        }

        .mic-btn:hover:not(:disabled) {
            background: #2d8a47;
            transform: scale(1.1);
        }

        .mic-btn.recording {
            background: var(--danger-color);
            animation: pulse 1.5s infinite;
        }

        .mic-btn:disabled {
            background: #5f6368;
            cursor: not-allowed;
        }

        .end-btn {
            background: var(--danger-color);
            color: white;
        }

        .end-btn:hover {
            background: #d33b2c;
            transform: scale(1.1);
        }

        .interview-ended {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.9);
            display: none;
            align-items: center;
            justify-content: center;
            z-index: 2000;
        }

        .interview-ended.show {
            display: flex;
        }

        .interview-ended-content {
            background: var(--card-bg);
            padding: 48px;
            border-radius: 16px;
            text-align: center;
            max-width: 500px;
            width: 90%;
            border: 1px solid var(--border-color);
        }

        .interview-ended h3 {
            color: var(--text-light);
            margin-bottom: 16px;
            font-size: 24px;
        }

        .interview-ended p {
            color: var(--text-muted);
            margin-bottom: 32px;
            font-size: 16px;
            line-height: 1.5;
        }

        .result-btn {
            background: var(--primary-color);
            color: white;
            border: none;
            padding: 16px 32px;
            border-radius: 8px;
            font-size: 16px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .result-btn:hover {
            background: #1557b0;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(26, 115, 232, 0.3);
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }

        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .transcript-content::-webkit-scrollbar {
            width: 6px;
        }

        .transcript-content::-webkit-scrollbar-track {
            background: var(--dark-bg);
        }

        .transcript-content::-webkit-scrollbar-thumb {
            background: var(--border-color);
            border-radius: 3px;
        }

        @media (max-width: 1024px) {
            .video-container {
                grid-template-columns: 1fr;
                grid-template-rows: 1fr 1fr;
                height: 35vh;
            }
            
            .participant-avatar {
                width: 120px;
                height: 120px;
                font-size: 48px;
            }
            
            .transcript-content {
                min-height: 150px;
            }
        }

        @media (max-width: 768px) {
            .interview-header {
                padding: 8px 16px;
            }
            
            .interview-title {
                font-size: 16px;
            }
            
            .timer-display {
                font-size: 18px;
            }
            
            .video-container {
                padding: 12px;
                gap: 8px;
            }
            
            .participant-avatar {
                width: 100px;
                height: 100px;
                font-size: 40px;
            }
            
            .controls-bar {
                padding: 16px;
            }
            
            .control-btn {
                width: 48px;
                height: 48px;
                font-size: 20px;
            }
            
            .video-container {
                height: 30vh;
            }
            
            .transcript-content {
                min-height: 120px;
                padding: 12px 16px;
            }
        }
    </style>
</head>
<body>
    <!-- Header -->
    <div class="interview-header">
        <div class="interview-info">
            <h1 class="interview-title">AI Interview Session</h1>
            <span class="job-title">{{ interview.job.title|default:"Software Developer" }}</span>
        </div>
        <div class="interview-timer">
            <div class="question-counter" id="questionCounter">Question 1/8</div>
            <div class="timer-display" id="timerDisplay">25:00</div>
        </div>
    </div>

    <!-- Main Container -->
    <div class="main-container">
        <!-- Video Container -->
        <div class="video-container">
            <!-- AI Interviewer -->
            <div class="video-participant ai-interviewer" id="aiInterviewer">
                <div class="participant-avatar" id="aiAvatar">
                    <i class="fas fa-robot"></i>
                </div>
                <div class="participant-name">Alex - AI Interviewer</div>
                <div class="participant-status" id="aiStatus">Speaking</div>
            </div>

            <!-- Candidate -->
            <div class="video-participant candidate-video" id="candidateVideo">
                <div class="participant-avatar" id="candidateAvatar">
                    <i class="fas fa-user"></i>
                </div>
                <div class="participant-name">{{ request.user.first_name|default:"You" }} - Candidate</div>
                <div class="participant-status" id="candidateStatus">Listening</div>
                <div class="recording-indicator" id="recordingIndicator">
                    <i class="fas fa-circle"></i>
                    Recording
                </div>
            </div>
        </div>

        <!-- Bottom Section -->
        <div class="bottom-section">
            <div class="transcript-header">
                <div class="transcript-title">Interview Transcript</div>
                <button class="transcript-toggle" id="transcriptToggle">
                    <i class="fas fa-chevron-up"></i>
                    Hide Transcript
                </button>
            </div>
            
            <div class="transcript-content" id="transcriptContent">
                <div class="current-question" id="currentQuestion">
                    <div class="audio-status unavailable" id="audioStatus">
                        <i class="fas fa-volume-mute"></i> No Audio
                    </div>
                    <div class="current-question-title">Current Question:</div>
                    <div class="current-question-text" id="currentQuestionText">
                        {{ ai_question|default:"Hello! Welcome to your AI interview. I'm excited to learn more about you. Can you tell me about yourself and why you're interested in this position?" }}
                    </div>
                </div>
                
                <div class="transcript-message interviewer">
                    <div class="message-avatar">
                        <i class="fas fa-robot"></i>
                    </div>
                    <div class="message-content">
                        <div class="message-header">
                            <div class="message-name">AI Interviewer</div>
                            <div class="message-time" id="firstMessageTime"></div>
                        </div>
                        <div class="message-text">{{ ai_question|default:"Hello! Welcome to your AI interview. I'm excited to learn more about you. Can you tell me about yourself and why you're interested in this position?" }}</div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Controls -->
        <div class="controls-bar">
            <button class="control-btn mic-btn" id="micBtn" title="Start Speaking">
                <i class="fas fa-microphone"></i>
            </button>
            <button class="control-btn end-btn" id="endBtn" title="End Interview">
                <i class="fas fa-phone-slash"></i>
            </button>
        </div>
    </div>

    <!-- Interview Ended Modal -->
    <div class="interview-ended" id="interviewEnded">
        <div class="interview-ended-content">
            <h3><i class="fas fa-check-circle text-success me-2"></i>Interview Completed!</h3>
            <p>Thank you for participating in the AI interview. Your responses have been recorded and will be reviewed by our team.</p>
            <button class="result-btn" id="viewResultsBtn">
                <i class="fas fa-chart-bar me-2"></i>View Results
            </button>
        </div>
    </div>

    <!-- Hidden Audio Element -->
    <audio id="aiAudio" preload="auto"></audio>
    
    <!-- CSRF Token -->
    {% csrf_token %}
    <input type="hidden" name="csrfmiddlewaretoken" value="{{ csrf_token }}">



<script>
// Global variables
let recognition = null;
let isListening = false;
let isInterviewActive = true;
let questionCount = 1;
let timeRemaining = 25 * 60; // 25 minutes in seconds
let timerInterval = null;
let audioContext = null;
let hasPlayedInitialAudio = false; // Flag to prevent duplicate audio playback

// DOM Elements
const micBtn = document.getElementById('micBtn');
const endBtn = document.getElementById('endBtn');
const aiAvatar = document.getElementById('aiAvatar');
const candidateAvatar = document.getElementById('candidateAvatar');
const aiInterviewer = document.getElementById('aiInterviewer');
const candidateVideo = document.getElementById('candidateVideo');
const aiStatus = document.getElementById('aiStatus');
const candidateStatus = document.getElementById('candidateStatus');
const aiAudio = document.getElementById('aiAudio');
const recordingIndicator = document.getElementById('recordingIndicator');
const transcriptContent = document.getElementById('transcriptContent');
const transcriptToggle = document.getElementById('transcriptToggle');
const currentQuestionText = document.getElementById('currentQuestionText');
const questionCounter = document.getElementById('questionCounter');
const timerDisplay = document.getElementById('timerDisplay');
const interviewEnded = document.getElementById('interviewEnded');
const viewResultsBtn = document.getElementById('viewResultsBtn');
const firstMessageTime = document.getElementById('firstMessageTime');
const audioStatus = document.getElementById('audioStatus');

// Get CSRF token with fallback
function getCSRFToken() {
    // Try to get from hidden input first
    const csrfInput = document.querySelector('[name=csrfmiddlewaretoken]');
    if (csrfInput && csrfInput.value) {
        return csrfInput.value;
    }
    
    // Fallback to cookie method
    const cookies = document.cookie.split(';');
    for (let cookie of cookies) {
        const [name, value] = cookie.trim().split('=');
        if (name === 'csrftoken') {
            return value;
        }
    }
    
    // Last resort - try meta tag
    const csrfMeta = document.querySelector('meta[name=csrf-token]');
    if (csrfMeta) {
        return csrfMeta.getAttribute('content');
    }
    
    console.warn('âš ï¸ CSRF token not found');
    return '';
}

// Refresh CSRF token from server
async function refreshCSRFToken() {
    try {
        const response = await fetch('/get-csrf-token/', {
            method: 'GET',
            credentials: 'same-origin'
        });
        
        if (response.ok) {
            const data = await response.json();
            const csrfInput = document.querySelector('[name=csrfmiddlewaretoken]');
            const csrfMeta = document.querySelector('meta[name=csrf-token]');
            
            if (csrfInput) csrfInput.value = data.csrf_token;
            if (csrfMeta) csrfMeta.setAttribute('content', data.csrf_token);
            
            console.log('âœ… CSRF token refreshed');
            return data.csrf_token;
        }
    } catch (error) {
        console.error('âŒ Failed to refresh CSRF token:', error);
    }
    return null;
}

// Initialize timer
function startTimer() {
    timerInterval = setInterval(() => {
        timeRemaining--;
        updateTimerDisplay();
        
        if (timeRemaining <= 0) {
            endInterview();
        }
    }, 1000);
}

function updateTimerDisplay() {
    const minutes = Math.floor(timeRemaining / 60);
    const seconds = timeRemaining % 60;
    timerDisplay.textContent = `${minutes}:${seconds.toString().padStart(2, '0')}`;
    
    // Change color when time is low
    if (timeRemaining <= 300) { // 5 minutes
        timerDisplay.style.color = '#ea4335';
    } else if (timeRemaining <= 600) { // 10 minutes
        timerDisplay.style.color = '#fbbc04';
    }
}

// Update participant status
function updateParticipantStatus(isAISpeaking, isCandidateSpeaking) {
    console.log(`ðŸ‘¥ Status update: AI=${isAISpeaking}, Candidate=${isCandidateSpeaking}`);
    
    // Update AI status
    if (isAISpeaking) {
        aiInterviewer.classList.add('speaking');
        aiAvatar.classList.add('speaking');
        aiStatus.textContent = 'Speaking';
        aiStatus.className = 'participant-status status-speaking';
    } else {
        aiInterviewer.classList.remove('speaking');
        aiAvatar.classList.remove('speaking');
        aiStatus.textContent = 'Listening';
        aiStatus.className = 'participant-status status-listening';
    }

    // Update candidate status
    if (isCandidateSpeaking) {
        candidateVideo.classList.add('speaking');
        candidateAvatar.classList.add('speaking');
        candidateStatus.textContent = 'Speaking';
        candidateStatus.className = 'participant-status status-speaking';
        recordingIndicator.classList.add('active');
    } else {
        candidateVideo.classList.remove('speaking');
        candidateAvatar.classList.remove('speaking');
        candidateStatus.textContent = 'Listening';
        candidateStatus.className = 'participant-status status-listening';
        recordingIndicator.classList.remove('active');
    }
}

// Update audio status indicator
function updateAudioStatus(status, message = '') {
    if (!audioStatus) return;
    
    audioStatus.className = 'audio-status';
    
    switch (status) {
        case 'available':
            audioStatus.classList.add('available');
            audioStatus.innerHTML = '<i class="fas fa-volume-up"></i> Audio On';
            break;
        case 'unavailable':
            audioStatus.classList.add('unavailable');
            audioStatus.innerHTML = '<i class="fas fa-volume-mute"></i> No Audio';
            break;
        case 'error':
            audioStatus.classList.add('error');
            audioStatus.innerHTML = '<i class="fas fa-exclamation-triangle"></i> Audio Error';
            break;
        case 'loading':
            audioStatus.classList.add('unavailable');
            audioStatus.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Loading...';
            break;
    }
    
    if (message) {
        audioStatus.title = message;
    }
}

// Add message to transcript with improved scrolling
function addTranscriptMessage(content, isUser = false) {
    const messageDiv = document.createElement('div');
    messageDiv.className = `transcript-message ${isUser ? 'candidate' : 'interviewer'}`;
    
    const currentTime = new Date().toLocaleTimeString('en-US', {
        hour12: false,
        hour: '2-digit',
        minute: '2-digit'
    });
    
    messageDiv.innerHTML = `
        <div class="message-avatar">
            <i class="fas fa-${isUser ? 'user' : 'robot'}"></i>
        </div>
        <div class="message-content">
            <div class="message-header">
                <div class="message-name">${isUser ? 'You' : 'AI Interviewer'}</div>
                <div class="message-time">${currentTime}</div>
            </div>
            <div class="message-text">${content}</div>
        </div>
    `;
    
    transcriptContent.appendChild(messageDiv);
    
    // Smooth scroll to bottom
    setTimeout(() => {
        transcriptContent.scrollTo({
            top: transcriptContent.scrollHeight,
            behavior: 'smooth'
        });
    }, 100);
    
    // Update current question if it's from interviewer
    if (!isUser && questionCount <= 8) {
        currentQuestionText.textContent = content;
    }
}

// Initialize audio context
async function initializeAudio() {
    try {
        if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
        
        if (audioContext.state === 'suspended') {
            await audioContext.resume();
            console.log('âœ… Audio context resumed');
        }
        
        console.log('âœ… Audio context initialized:', audioContext.state);
        return true;
    } catch (error) {
        console.error('âŒ Audio initialization failed:', error);
        return false;
    }
}

// Enhanced audio playing function with better debugging
async function playAIResponse(audioUrl) {
    if (!audioUrl || audioUrl === 'None' || audioUrl === null || audioUrl === '' || audioUrl === 'null' || audioUrl === 'undefined') {
        console.log('âŒ No valid audio URL provided:', audioUrl);
        updateParticipantStatus(false, false);
        return;
    }
    
    // Stop any currently playing audio to prevent overlaps
    if (aiAudio && !aiAudio.paused) {
        console.log('ðŸ›‘ Stopping currently playing audio');
        aiAudio.pause();
        aiAudio.currentTime = 0;
    }
    
    try {
        updateParticipantStatus(true, false);
        console.log('ðŸ”Š Attempting to play audio:', audioUrl);
        console.log('ðŸ”Š Audio URL type:', typeof audioUrl);
        console.log('ðŸ”Š Audio URL length:', audioUrl.length);
        
        // Ensure audio context is active
        await initializeAudio();
        
        // Clean the URL and add timestamp
        let cleanUrl = audioUrl.trim();
        if (!cleanUrl.startsWith('http') && !cleanUrl.startsWith('/')) {
            cleanUrl = '/' + cleanUrl;
        }
        
        const audioUrlWithTimestamp = cleanUrl.includes('?') ? 
            `${cleanUrl}&t=${new Date().getTime()}` : 
            `${cleanUrl}?t=${new Date().getTime()}`;
        
        console.log('ðŸ”Š Final audio URL:', audioUrlWithTimestamp);
        
        // Test if URL is accessible
        try {
            const testResponse = await fetch(audioUrlWithTimestamp, { method: 'HEAD' });
            console.log('ðŸ”Š Audio URL test response:', testResponse.status, testResponse.statusText);
            if (!testResponse.ok) {
                throw new Error(`Audio file not accessible: ${testResponse.status}`);
            }
        } catch (fetchError) {
            console.error('âŒ Audio URL not accessible:', fetchError);
            updateParticipantStatus(false, false);
            return;
        }
        
        // Reset audio element
        aiAudio.pause();
        aiAudio.currentTime = 0;
        aiAudio.src = audioUrlWithTimestamp;
        
        // Add comprehensive error handling
        aiAudio.onerror = (e) => {
            console.error('âŒ Audio element error:', e);
            console.error('âŒ Audio src:', aiAudio.src);
            console.error('âŒ Audio error details:', {
                code: aiAudio.error?.code,
                message: aiAudio.error?.message,
                readyState: aiAudio.readyState,
                networkState: aiAudio.networkState
            });
            updateParticipantStatus(false, false);
        };
        
        aiAudio.oncanplaythrough = () => {
            console.log('âœ… Audio can play through');
        };
        
        aiAudio.onloadstart = () => {
            console.log('ðŸ”„ Audio loading started');
        };
        
        aiAudio.onloadeddata = () => {
            console.log('âœ… Audio data loaded, duration:', aiAudio.duration);
        };
        
        // Load the audio
        aiAudio.load();
        
        // Wait for audio to be ready with better timeout handling
        await new Promise((resolve, reject) => {
            const timeout = setTimeout(() => {
                console.error('âŒ Audio loading timeout after 15 seconds');
                reject(new Error('Audio loading timeout'));
            }, 15000); // 15 second timeout
            
            aiAudio.oncanplay = () => {
                console.log('âœ… Audio ready to play, duration:', aiAudio.duration);
                clearTimeout(timeout);
                resolve();
            };
            
            aiAudio.onerror = (e) => {
                console.error('âŒ Audio loading error:', e);
                clearTimeout(timeout);
                reject(new Error('Audio loading failed'));
            };
        });
        
        // Play the audio with volume check
        aiAudio.volume = 1.0;
        console.log('ðŸ”Š Audio volume set to:', aiAudio.volume);
        
        const playPromise = aiAudio.play();
        
        if (playPromise !== undefined) {
            await playPromise;
            console.log('âœ… Audio playing successfully, current time:', aiAudio.currentTime);
        }
        
        // Set up end handler
        aiAudio.onended = () => {
            console.log('ðŸ”Š Audio finished playing');
            updateParticipantStatus(false, false);
        };
        
        // Update audio status to show it's playing
        updateAudioStatus('available', 'Audio is playing');
        
        // Monitor playback
        const playbackMonitor = setInterval(() => {
            if (aiAudio.paused || aiAudio.ended) {
                clearInterval(playbackMonitor);
                updateAudioStatus('unavailable', 'Audio finished');
                return;
            }
            console.log('ðŸ”Š Audio playing... current time:', aiAudio.currentTime, '/', aiAudio.duration);
        }, 1000);
        
    } catch (error) {
        console.error('âŒ Audio playback failed:', error);
        console.error('âŒ Audio details:', {
            url: audioUrl,
            readyState: aiAudio.readyState,
            networkState: aiAudio.networkState,
            error: aiAudio.error,
            volume: aiAudio.volume,
            muted: aiAudio.muted
        });
        
        updateParticipantStatus(false, false);
        
        // Show user-friendly error message and update status
        updateAudioStatus('error', 'Audio playback failed');
        addTranscriptMessage("[Audio playback failed - please check your speakers/headphones]");
    }
}

// Initialize speech recognition
function initializeSpeechRecognition() {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        recognition = new SpeechRecognition();
        
        // Enhanced recognition settings
        recognition.lang = "en-US";
        recognition.interimResults = true;
        recognition.continuous = true;
        recognition.maxAlternatives = 1;

        recognition.onstart = function() {
            console.log('ðŸŽ¤ Speech recognition started');
            isListening = true;
            updateParticipantStatus(false, true);
            micBtn.classList.add('recording');
            micBtn.innerHTML = '<i class="fas fa-stop"></i>';
            micBtn.title = 'Stop Speaking';
        };

        recognition.onend = function() {
            console.log('ðŸŽ¤ Speech recognition ended');
            isListening = false;
            updateParticipantStatus(false, false);
            micBtn.classList.remove('recording');
            micBtn.innerHTML = '<i class="fas fa-microphone"></i>';
            micBtn.title = 'Start Speaking';
        };

        recognition.onresult = async function(event) {
            // Only process final results to avoid cutting off speech
            if (!event.results[event.results.length - 1].isFinal) {
                return;
            }
            
            const userText = event.results[event.results.length - 1][0].transcript;
            const confidence = event.results[event.results.length - 1][0].confidence;
            
            console.log('ðŸ—£ï¸ User said:', userText);
            console.log('ðŸ—£ï¸ Confidence:', confidence);
            
            // Stop recognition to prevent auto-restart
            recognition.stop();
            
            addTranscriptMessage(userText, true);

            // Disable mic during processing
            micBtn.disabled = true;
            micBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i>';

            try {
                console.log('ðŸ“¤ Sending user response to server...');
                
                const formData = new URLSearchParams();
                formData.append('text', userText);
                
                const csrfToken = getCSRFToken();
                console.log('ðŸ” Using CSRF token:', csrfToken ? 'Found' : 'Missing');
                
                const response = await fetch(window.location.href, {
                    method: "POST",
                    headers: {
                        'Content-Type': 'application/x-www-form-urlencoded',
                        'X-CSRFToken': csrfToken,
                        'X-Requested-With': 'XMLHttpRequest'
                    },
                    body: formData
                });
                
                if (!response.ok) {
                    if (response.status === 403) {
                        console.error('âŒ CSRF token error - attempting refresh');
                        
                        // Try to refresh CSRF token first
                        const newToken = await refreshCSRFToken();
                        if (newToken) {
                            console.log('ðŸ”„ Retrying request with new CSRF token');
                            // Retry the request with new token
                            const retryFormData = new URLSearchParams();
                            retryFormData.append('text', userText);
                            
                            const retryResponse = await fetch(window.location.href, {
                                method: "POST",
                                headers: {
                                    'Content-Type': 'application/x-www-form-urlencoded',
                                    'X-CSRFToken': newToken,
                                    'X-Requested-With': 'XMLHttpRequest'
                                },
                                body: retryFormData
                            });
                            
                            if (retryResponse.ok) {
                                const retryData = await retryResponse.json();
                                console.log('âœ… Retry successful:', retryData);
                                // Process the successful response
                                if (retryData.question_count) {
                                    questionCount = retryData.question_count;
                                } else {
                                    questionCount++; // Fallback increment
                                }
                                questionCounter.textContent = `Question ${questionCount}/8`;
                                console.log(`ðŸ“Š Retry - Updated question counter: ${questionCount}/8`);
                                addTranscriptMessage(retryData.response);
                                if (retryData.audio && retryData.audio !== '') {
                                    await playAIResponse(retryData.audio);
                                } else {
                                    updateParticipantStatus(false, false);
                                }
                                if (retryData.is_final || questionCount >= 8) {
                                    console.log(`ðŸ Retry - Interview ending: is_final=${retryData.is_final}, questionCount=${questionCount}`);
                                    setTimeout(() => endInterview(), 3000);
                                }
                                return;
                            }
                        }
                        
                        // If refresh failed, show reload prompt
                        alert('Session expired. The page will refresh to restore your session.');
                        window.location.reload();
                        return;
                    }
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }
                
                const data = await response.json();
                console.log('ðŸ“¥ Server response:', data);
                
                // Handle CSRF errors from server response
                if (data.csrf_error || data.refresh_required) {
                    console.error('ðŸ”’ Server reported CSRF error');
                    addTranscriptMessage(data.response || "Your session has expired. Please refresh the page to continue.");
                    
                    setTimeout(() => {
                        if (confirm('Your session has expired. Would you like to refresh the page to continue?')) {
                            window.location.reload();
                        }
                    }, 2000);
                    return;
                }
                
                // Update question count - force update
                if (data.question_count) {
                    questionCount = data.question_count;
                } else {
                    questionCount++; // Fallback increment
                }
                questionCounter.textContent = `Question ${questionCount}/8`;
                console.log(`ðŸ“Š Updated question counter: ${questionCount}/8`);
                
                // Add AI response to transcript
                addTranscriptMessage(data.response);

                // Play audio response
                if (data.audio && data.audio !== '') {
                    console.log('ðŸ”Š Playing response audio:', data.audio);
                    await playAIResponse(data.audio);
                } else {
                    console.log('âš ï¸ No audio in response');
                    updateParticipantStatus(false, false);
                }
                
                // Check if interview should end
                if (data.is_final || questionCount >= 8) {
                    console.log(`ðŸ Interview ending: is_final=${data.is_final}, questionCount=${questionCount}`);
                    setTimeout(() => {
                        endInterview();
                    }, 3000);
                }
                
            } catch (error) {
                console.error('âŒ Request failed:', error);
                
                // Check if it's a CSRF error
                if (error.message && error.message.includes('403')) {
                    console.error('ðŸ”’ CSRF token error detected');
                    addTranscriptMessage("Your session has expired. Please refresh the page to continue.");
                    
                    // Show refresh prompt after a delay
                    setTimeout(() => {
                        if (confirm('Your session has expired. Would you like to refresh the page to continue?')) {
                            window.location.reload();
                        }
                    }, 2000);
                } else {
                    addTranscriptMessage("Sorry, I encountered a technical issue. Please try again.");
                }
                
                updateParticipantStatus(false, false);
            } finally {
                // Re-enable mic
                micBtn.disabled = false;
                micBtn.classList.remove('recording');
                micBtn.innerHTML = '<i class="fas fa-microphone"></i>';
                micBtn.title = 'Start Speaking';
            }
        };
        
        recognition.onerror = function(event) {
            console.error('âŒ Speech recognition error:', event.error);
            updateParticipantStatus(false, false);
            micBtn.classList.remove('recording');
            micBtn.innerHTML = '<i class="fas fa-microphone"></i>';
            micBtn.disabled = false;
            isListening = false;
            
            if (event.error === 'not-allowed') {
                alert('Microphone permission denied. Please allow microphone access and refresh the page.');
            } else if (event.error === 'no-speech') {
                console.log('âš ï¸ No speech detected');
            }
        };
        
        console.log('âœ… Speech recognition initialized');
        return true;
        
    } else {
        alert("Voice input not supported in your browser. Please use Google Chrome or Firefox.");
        return false;
    }
}

// End interview function
function endInterview() {
    console.log('ðŸ Ending interview...');
    isInterviewActive = false;
    
    if (timerInterval) {
        clearInterval(timerInterval);
    }
    
    if (recognition && isListening) {
        recognition.stop();
    }
    
    // Stop any playing audio
    if (aiAudio) {
        aiAudio.pause();
        aiAudio.currentTime = 0;
    }
    
    micBtn.disabled = true;
    endBtn.disabled = true;
    updateParticipantStatus(false, false);
    
    // Show interview ended modal
    interviewEnded.classList.add('show');
}

// Toggle transcript visibility
transcriptToggle.addEventListener('click', () => {
    const isCollapsed = transcriptContent.classList.contains('collapsed');
    
    if (isCollapsed) {
        transcriptContent.classList.remove('collapsed');
        transcriptToggle.innerHTML = '<i class="fas fa-chevron-up"></i> Hide Transcript';
    } else {
        transcriptContent.classList.add('collapsed');
        transcriptToggle.innerHTML = '<i class="fas fa-chevron-down"></i> Show Transcript';
    }
});

// Event listeners
micBtn.addEventListener('click', async () => {
    if (!isInterviewActive) return;
    
    // Initialize audio context on first user interaction
    await initializeAudio();
    
    if (recognition && !isListening) {
        try {
            recognition.start();
        } catch (error) {
            console.error('âŒ Failed to start recognition:', error);
        }
    } else if (isListening) {
        recognition.stop();
    }
});

endBtn.addEventListener('click', () => {
    if (confirm('Are you sure you want to end the interview?')) {
        endInterview();
    }
});

viewResultsBtn.addEventListener('click', () => {
    // Extract UUID from current URL and redirect to results
    const pathParts = window.location.pathname.split('/');
    const uuid = pathParts[pathParts.length - 2]; // Assuming URL ends with /uuid/
    window.location.href = `/interview-results/${uuid}/`;
});

// Request camera and microphone permissions and show video
async function requestPermissions() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
            video: true, 
            audio: true 
        });
        console.log('âœ… Camera and microphone permissions granted');
        
        // Create video element and show camera feed
        const candidateVideo = document.getElementById('candidateVideo');
        let videoElement = candidateVideo.querySelector('video');
        
        if (!videoElement) {
            videoElement = document.createElement('video');
            videoElement.style.width = '100%';
            videoElement.style.height = '100%';
            videoElement.style.objectFit = 'cover';
            videoElement.style.borderRadius = '12px';
            videoElement.autoplay = true;
            videoElement.muted = true;
            videoElement.playsInline = true;
            
            // Replace avatar with video
            const avatar = candidateVideo.querySelector('.participant-avatar');
            if (avatar) {
                avatar.style.display = 'none';
            }
            candidateVideo.appendChild(videoElement);
        }
        
        videoElement.srcObject = stream;
        console.log('ðŸ“¹ Camera feed started');
        
        return true;
    } catch (error) {
        console.error('âŒ Permission denied:', error);
        alert('Please allow camera and microphone access for the interview to work properly.');
        return false;
    }
}

// Initialize everything when DOM is ready
document.addEventListener('DOMContentLoaded', async () => {
    console.log('ðŸš€ Initializing interview system...');
    
    // Request permissions first
    await requestPermissions();
    
    // Set first message time
    const currentTime = new Date().toLocaleTimeString('en-US', {
        hour12: false,
        hour: '2-digit',
        minute: '2-digit'
    });
    if (firstMessageTime) {
        firstMessageTime.textContent = currentTime;
    }
    
    // Initialize systems
    const speechInitialized = initializeSpeechRecognition();
    if (!speechInitialized) {
        micBtn.disabled = true;
        micBtn.title = 'Speech recognition not supported';
    }
    
    // Initialize participant status
    updateParticipantStatus(false, false);
    
    // Initialize audio status
    updateAudioStatus('loading', 'Checking audio system...');
    
    // Start timer
    startTimer();
    
    // Handle initial audio playback with better debugging
    const initialAudio = `{{ audio_url|safe }}`;
    console.log('ðŸ”Š Initial audio check:', {
        url: initialAudio,
        type: typeof initialAudio,
        length: initialAudio?.length,
        isEmpty: initialAudio === '',
        isNone: initialAudio === 'None',
        isNull: initialAudio === 'null',
        raw: '{{ audio_url }}'
    });
    
    // Test TTS system health
    console.log('ðŸ”§ Testing TTS system...');
    try {
        const ttsTestResponse = await fetch('/test-tts/', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-CSRFToken': getCSRFToken()
            },
            body: JSON.stringify({ text: 'Test audio generation' })
        });
        
        if (ttsTestResponse.ok) {
            const ttsData = await ttsTestResponse.json();
            console.log('âœ… TTS system test result:', ttsData);
        } else {
            console.error('âŒ TTS system test failed:', ttsTestResponse.status);
        }
    } catch (ttsError) {
        console.error('âŒ TTS system test error:', ttsError);
    }
    
    if (initialAudio && 
        initialAudio !== 'None' && 
        initialAudio !== '' && 
        initialAudio !== 'null' && 
        initialAudio !== 'undefined' &&
        !initialAudio.includes('None') &&
        initialAudio.trim().length > 0 &&
        !hasPlayedInitialAudio) {
        
        console.log('âœ… Valid initial audio found');
        hasPlayedInitialAudio = true; // Set flag to prevent duplicate playback
        
        // Create a function to play initial audio
        const playInitialAudio = async () => {
            try {
                console.log('ðŸ”Š Attempting to play initial audio...');
                await playAIResponse(initialAudio);
            } catch (error) {
                console.error('âŒ Initial audio playback failed:', error);
                // Add error message to transcript
                addTranscriptMessage("[Audio system error - please check if your speakers are working]");
            }
        };
        
        // Try to play after a short delay
        setTimeout(() => {
            playInitialAudio();
        }, 2000);
        
        // Also set up click handler for autoplay restrictions (but only once)
        const enableAudioOnInteraction = async () => {
            if (!hasPlayedInitialAudio) {
                hasPlayedInitialAudio = true;
                await initializeAudio();
                playInitialAudio();
            }
        };
        
        // Listen for any user interaction (only once)
        const interactionEvents = ['click', 'touchstart', 'keydown'];
        const removeListeners = () => {
            interactionEvents.forEach(event => {
                document.removeEventListener(event, enableAudioOnInteraction);
            });
        };
        
        interactionEvents.forEach(event => {
            document.addEventListener(event, () => {
                enableAudioOnInteraction();
                removeListeners();
            }, { once: true });
        });
        
    } else {
        console.log('âš ï¸ No valid initial audio found');
        console.log('ðŸ” Raw template value:', '{{ audio_url }}');
        
        // Update audio status and add message to transcript
        updateAudioStatus('unavailable', 'TTS system offline or no audio generated');
        addTranscriptMessage("[No audio available - you can continue with text-based interview]");
        
        // Try to generate audio for the current question
        const currentQuestionTextContent = currentQuestionText.textContent;
        if (currentQuestionTextContent) {
            console.log('ðŸ”„ Attempting to generate audio for current question...');
            updateAudioStatus('loading', 'Generating audio...');
            
            try {
                const audioGenResponse = await fetch('/generate-audio/', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'X-CSRFToken': getCSRFToken()
                    },
                    body: JSON.stringify({ text: currentQuestionTextContent })
                });
                
                if (audioGenResponse.ok) {
                    const audioData = await audioGenResponse.json();
                    if (audioData.success && audioData.audio_url) {
                        console.log('âœ… Generated audio for current question:', audioData.audio_url);
                        updateAudioStatus('available', 'Audio generated successfully');
                        await playAIResponse(audioData.audio_url);
                    } else {
                        console.error('âŒ Audio generation failed:', audioData.error);
                        updateAudioStatus('error', audioData.error || 'Audio generation failed');
                    }
                } else {
                    console.error('âŒ Audio generation request failed:', audioGenResponse.status);
                    updateAudioStatus('error', 'Audio generation service unavailable');
                }
            } catch (genError) {
                console.error('âŒ Failed to generate audio:', genError);
                updateAudioStatus('error', 'Audio generation error: ' + genError.message);
            }
        }
    }
    
    console.log('âœ… Interview system initialization complete');
});

// Handle page visibility changes
document.addEventListener('visibilitychange', () => {
    if (document.hidden && isListening) {
        console.log('âš ï¸ Page hidden while listening, stopping recognition');
        if (recognition) {
            recognition.stop();
        }
    }
});

// Prevent page refresh during active interview
window.addEventListener('beforeunload', (e) => {
    if (isInterviewActive) {
        e.preventDefault();
        e.returnValue = 'Your interview is still in progress. Are you sure you want to leave?';
        return e.returnValue;
    }
});

// Handle audio context suspension (mobile browsers)
document.addEventListener('visibilitychange', async () => {
    if (!document.hidden && audioContext && audioContext.state === 'suspended') {
        try {
            await audioContext.resume();
            console.log('âœ… Audio context resumed after visibility change');
        } catch (error) {
            console.error('âŒ Failed to resume audio context:', error);
        }
    }
});

// Error handling for network issues
window.addEventListener('online', () => {
    console.log('âœ… Network connection restored');
});

window.addEventListener('offline', () => {
    console.log('âš ï¸ Network connection lost');
    if (isListening && recognition) {
        recognition.stop();
    }
});

// Debug function to test audio with comprehensive checks
function testAudio() {
    console.log('ðŸ”§ Testing audio system...');
    const testUrl = '{{ audio_url|safe }}';
    console.log('Test URL:', testUrl);
    
    // Test audio element
    console.log('Audio element state:', {
        readyState: aiAudio.readyState,
        networkState: aiAudio.networkState,
        volume: aiAudio.volume,
        muted: aiAudio.muted,
        paused: aiAudio.paused
    });
    
    // Test audio context
    console.log('Audio context state:', audioContext?.state);
    
    // Test URL accessibility
    if (testUrl && testUrl !== 'None') {
        fetch(testUrl, { method: 'HEAD' })
            .then(response => {
                console.log('URL accessibility test:', response.status, response.statusText);
                if (response.ok) {
                    playAIResponse(testUrl);
                } else {
                    console.error('URL not accessible');
                }
            })
            .catch(error => {
                console.error('URL test failed:', error);
            });
    } else {
        console.log('No valid test URL available');
    }
}

// Debug function to test TTS generation
async function testTTSGeneration() {
    console.log('ðŸ”§ Testing TTS generation...');
    try {
        const response = await fetch('/test-tts/', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-CSRFToken': getCSRFToken()
            },
            body: JSON.stringify({ text: 'This is a test of the text to speech system' })
        });
        
        if (response.ok) {
            const data = await response.json();
            console.log('âœ… TTS generation test result:', data);
            if (data.audio_url) {
                await playAIResponse(data.audio_url);
            }
        } else {
            console.error('âŒ TTS generation test failed:', response.status);
        }
    } catch (error) {
        console.error('âŒ TTS generation test error:', error);
    }
}

// Debug function to check microphone permissions
async function checkMicrophonePermission() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        console.log('âœ… Microphone permission granted');
        stream.getTracks().forEach(track => track.stop());
        return true;
    } catch (error) {
        console.error('âŒ Microphone permission denied:', error);
        return false;
    }
}

// Expose debug functions to global scope for testing
window.interviewDebug = {
    testAudio,
    testTTSGeneration,
    checkMicrophonePermission,
    playAIResponse,
    initializeAudio,
    getAudioState: () => ({
        audioContext: audioContext?.state,
        aiAudioReady: aiAudio?.readyState,
        aiAudioNetwork: aiAudio?.networkState,
        aiAudioSrc: aiAudio?.src,
        aiAudioVolume: aiAudio?.volume,
        aiAudioMuted: aiAudio?.muted,
        isListening,
        isInterviewActive
    }),
    getCurrentQuestion: () => currentQuestionText.textContent,
    getTranscriptHeight: () => transcriptContent.scrollHeight,
    scrollToBottom: () => transcriptContent.scrollTop = transcriptContent.scrollHeight,
    updateAudioStatus: updateAudioStatus,
    checkAudioSystem: async () => {
        console.log('ðŸ”§ Checking audio system...');
        
        // Check audio element
        console.log('Audio element:', {
            readyState: aiAudio.readyState,
            networkState: aiAudio.networkState,
            volume: aiAudio.volume,
            muted: aiAudio.muted
        });
        
        // Check audio context
        if (audioContext) {
            console.log('Audio context state:', audioContext.state);
        } else {
            console.log('Audio context not initialized');
        }
        
        // Test TTS system
        try {
            const response = await fetch('/test-tts/', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'X-CSRFToken': getCSRFToken()
                },
                body: JSON.stringify({ text: 'Audio system test' })
            });
            
            if (response.ok) {
                const data = await response.json();
                console.log('TTS system test result:', data);
                return data;
            } else {
                console.error('TTS system test failed:', response.status);
                return { success: false, error: 'TTS system unavailable' };
            }
        } catch (error) {
            console.error('TTS system test error:', error);
            return { success: false, error: error.message };
        }
    }
};

console.log('ðŸ”§ Debug functions available at window.interviewDebug');
console.log('ðŸ”§ Available debug commands:');
console.log('  - window.interviewDebug.testAudio() - Test audio playback');
console.log('  - window.interviewDebug.testTTSGeneration() - Test TTS generation');
console.log('  - window.interviewDebug.checkAudioSystem() - Check audio system health');
console.log('  - window.interviewDebug.getAudioState() - Get audio system state');
console.log('  - window.interviewDebug.updateAudioStatus(status, message) - Update audio status');
console.log('  - window.interviewDebug.scrollToBottom() - Scroll transcript to bottom');

// Auto-run audio system check
setTimeout(async () => {
    const audioCheck = await window.interviewDebug.checkAudioSystem();
    if (audioCheck.success) {
        console.log('âœ… Audio system check passed');
    } else {
        console.log('âŒ Audio system check failed:', audioCheck.error);
        updateAudioStatus('error', audioCheck.error);
    }
}, 3000);
</script> 

  
 </body>
</html>  {% endcomment %}