{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AI Interview</title>

  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
  <link rel="stylesheet" href="{% static 'css/interviewlink.css' %}">

  <style>
    body {
      background: #f3f6f9;
      font-family: 'Segoe UI', sans-serif;
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      padding: 2rem;
    }

    .interview-room {
      background: white;
      border-radius: 10px;
      box-shadow: 0 0 20px rgba(0,0,0,0.1);
      max-width: 1000px;
      width: 100%;
      padding: 2rem;
    }

    .chat-area {
      height: 400px;
      overflow-y: auto;
      background: #f9f9f9;
      border-radius: 10px;
      padding: 1rem;
      margin-bottom: 1.5rem;
    }

    .chat-msg {
      margin-bottom: 1rem;
    }

    .chat-msg strong {
      display: block;
      margin-bottom: 0.25rem;
    }

    .chat-msg.ai {
      text-align: left;
    }

    .chat-msg.user {
      text-align: right;
    }

    .user-side,
    .ai-side {
      text-align: center;
    }

    .profile-box {
      border-radius: 10px;
      padding: 1rem;
      background: #e6f0ff;
    }

    .controls {
      display: flex;
      justify-content: center;
      gap: 1rem;
    }

    .status-indicator {
      padding: 0.5rem 1rem;
      border-radius: 5px;
      margin-bottom: 1rem;
      text-align: center;
      font-weight: bold;
    }

    .status-loading {
      background: #fff3cd;
      color: #856404;
      border: 1px solid #ffeeba;
    }

    .status-ready {
      background: #d4edda;
      color: #155724;
      border: 1px solid #c3e6cb;
    }

    .status-listening {
      background: #cce5ff;
      color: #004085;
      border: 1px solid #b8daff;
      animation: pulse 1.5s infinite;
    }

    @keyframes pulse {
      0% { opacity: 1; }
      50% { opacity: 0.7; }
      100% { opacity: 1; }
    }

    .btn:disabled {
      opacity: 0.6;
      cursor: not-allowed;
    }
  </style>
</head>
<body>

<div class="interview-room">
   <h2>AI Interview for {{ interview.candidate.username }}</h2>
  <h4 class="text-center mb-4">ü§ñ AI Interview for <span class="text-primary">{{ application.job.title }}</span></h4>

  <!-- Status Indicator -->
  <div class="status-indicator status-loading" id="statusIndicator">
    üîÑ Initializing interview...
  </div>

  <div class="row mb-4">
    <div class="col-md-6 user-side">
      <div class="profile-box">
        <h5>üë§ You</h5>
        <p>{% if request.user.is_authenticated %}{{ request.user.get_full_name }}{% else %}Guest User{% endif %}</p>
      </div>
    </div>
    <div class="col-md-6 ai-side">
      <div class="profile-box bg-light">
        <h5>ü§ñ AI Interviewer</h5>
        <p>Virtual HR Assistant</p>
      </div>
    </div>
  </div>

  <div class="chat-area" id="chatBox">
    <div class="chat-msg ai">
      <strong>AI:</strong>
      <span>{{ ai_question }}</span>
    </div>
  </div>

  <div class="controls">
    <button class="btn btn-success" id="startBtn" disabled>üéôÔ∏è Start Speaking</button>
    <button class="btn btn-danger" id="stopBtn" disabled>üõë Stop</button>
  </div>

  <!-- Hidden audio element -->
  <audio id="aiAudio" preload="auto"></audio>
</div>

<!-- Bootstrap JS -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>

<script>
  const startBtn = document.getElementById("startBtn");
  const stopBtn = document.getElementById("stopBtn");
  const chatBox = document.getElementById("chatBox");
  const aiAudio = document.getElementById("aiAudio");
  const statusIndicator = document.getElementById("statusIndicator");
  
  let audioContext = null;
  let audioEnabled = false;
  let recognition = null;
  let isListening = false;

  // Update status indicator
  function updateStatus(message, type = 'loading') {
    statusIndicator.textContent = message;
    statusIndicator.className = `status-indicator status-${type}`;
  }

  // Initialize audio context automatically
  async function initializeAudio() {
    try {
      // Create audio context
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      
      // Resume audio context if suspended
      if (audioContext.state === 'suspended') {
        await audioContext.resume();
      }
      
      audioEnabled = true;
      updateStatus("üéß Audio ready - Interview starting...", 'ready');
      
      return true;
    } catch (error) {
      console.error('Audio initialization failed:', error);
      updateStatus("‚ö†Ô∏è Audio unavailable - Interview will continue without sound", 'ready');
      return false;
    }
  }
  
  // Enhanced audio playback function for base64 data
  async function playAudio(audioData) {
    if (!audioData || audioData === 'None' || audioData === 'null') {
      console.log('No audio data provided');
      return;
    }
    
    try {
      // Ensure audio context is running
      if (audioContext && audioContext.state === 'suspended') {
        await audioContext.resume();
      }
      
      // Set the base64 data URL directly to audio source
      aiAudio.src = audioData;
      aiAudio.load(); // Force reload
      
      // Wait for audio to be ready
      await new Promise((resolve, reject) => {
        aiAudio.oncanplaythrough = resolve;
        aiAudio.onerror = (e) => {
          console.error('Audio load error:', e);
          resolve(); // Continue even if audio fails
        };
        
        // Timeout after 3 seconds
        setTimeout(() => resolve(), 3000);
      });
      
      // Play the audio
      const playPromise = aiAudio.play();
      if (playPromise !== undefined) {
        await playPromise;
        console.log('Audio played successfully');
      }
    } catch (error) {
      console.error('Audio playback failed:', error);
      // Continue without audio - don't block the interview
    }
  }

  // Initialize speech recognition
  function initializeSpeechRecognition() {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognition = new SpeechRecognition();
      recognition.lang = "en-US";
      recognition.interimResults = false;
      recognition.continuous = false;

      recognition.onstart = function() {
        isListening = true;
        updateStatus("üéôÔ∏è Listening... Please speak your answer", 'listening');
        startBtn.disabled = true;
        stopBtn.disabled = false;
      };

      recognition.onend = function() {
        isListening = false;
        updateStatus("ü§ñ Processing your response...", 'loading');
        startBtn.disabled = false;
        stopBtn.disabled = true;
      };

      recognition.onresult = async function(event) {
        const userText = event.results[0][0].transcript;
        chatBox.innerHTML += `
          <div class="chat-msg user">
            <strong>You:</strong>
            <span>${userText}</span>
          </div>`;

        chatBox.scrollTop = chatBox.scrollHeight;

        // Send to backend
        try {
          updateStatus("ü§ñ AI is thinking...", 'loading');
          
          const response = await fetch("", {
            method: "POST",
            headers: {
              'Content-Type': 'application/x-www-form-urlencoded',
              'X-CSRFToken': '{{ csrf_token }}'
            },
            body: new URLSearchParams({text: userText})
          });
          
          const data = await response.json();
          
          chatBox.innerHTML += `
            <div class="chat-msg ai">
              <strong>AI:</strong>
              <span>${data.response}</span>
            </div>`;

          // Play AI response audio (base64 data)
          if (data.audio && audioEnabled) {
            updateStatus("üîä Playing AI response...", 'ready');
            await playAudio(data.audio);
          }
          
          updateStatus("‚úÖ Ready for your next response", 'ready');
          chatBox.scrollTop = chatBox.scrollHeight;
          
        } catch (error) {
          console.error('Request failed:', error);
          chatBox.innerHTML += `
            <div class="chat-msg ai">
              <strong>AI:</strong>
              <span>Sorry, I encountered a technical issue. Please try again.</span>
            </div>`;
          updateStatus("‚ùå Error occurred - Ready to try again", 'ready');
        }
      };
      
      recognition.onerror = function(event) {
        console.error('Speech recognition error:', event.error);
        updateStatus("‚ùå Speech recognition error - Please try again", 'ready');
        isListening = false;
        startBtn.disabled = false;
        stopBtn.disabled = true;
      };
      
    } else {
      updateStatus("‚ùå Voice input not supported in this browser", 'ready');
      alert("Voice input not supported in your browser. Please use Google Chrome or Firefox.");
    }
  }

  // Auto-start the interview when page loads
  async function startInterview() {
    updateStatus("üîÑ Initializing audio system...", 'loading');
    
    // Initialize audio
    await initializeAudio();
    
    // Initialize speech recognition
    initializeSpeechRecognition();
    
    // Enable controls
    startBtn.disabled = false;
    stopBtn.disabled = true;
    
    // Auto-play the first question
    const initialAudioData = `{{ audio_url|safe }}`;
    if (initialAudioData && initialAudioData !== 'None' && initialAudioData !== 'null') {
      updateStatus("üîä Playing first question...", 'ready');
      await playAudio(initialAudioData);
      updateStatus("‚úÖ Ready for your response - Click 'Start Speaking'", 'ready');
    } else {
      updateStatus("‚úÖ Interview ready - Click 'Start Speaking' to begin", 'ready');
    }
  }

  // Button event handlers
  startBtn.onclick = () => {
    if (recognition && !isListening) {
      recognition.start();
    }
  };
  
  stopBtn.onclick = () => {
    if (recognition && isListening) {
      recognition.stop();
    }
  };

  // Auto-start interview when page loads
  document.addEventListener('DOMContentLoaded', () => {
    // Small delay to ensure everything is loaded
    setTimeout(startInterview, 500);
  });

  // Fallback: Try to initialize on any user interaction
  document.body.addEventListener('click', async () => {
    if (!audioEnabled) {
      await initializeAudio();
    }
  }, { once: true });
</script>

</body>
</html>




{% comment %} {% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AI Interview</title>

  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
  <link rel="stylesheet" href="{% static 'css/interviewlink.css' %}">

  <style>
    body {
      background: #f3f6f9;
      font-family: 'Segoe UI', sans-serif;
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      padding: 2rem;
    }

    .interview-room {
      background: white;
      border-radius: 10px;
      box-shadow: 0 0 20px rgba(0,0,0,0.1);
      max-width: 1000px;
      width: 100%;
      padding: 2rem;
    }

    .chat-area {
      height: 400px;
      overflow-y: auto;
      background: #f9f9f9;
      border-radius: 10px;
      padding: 1rem;
      margin-bottom: 1.5rem;
    }

    .chat-msg {
      margin-bottom: 1rem;
    }

    .chat-msg strong {
      display: block;
      margin-bottom: 0.25rem;
    }

    .chat-msg.ai {
      text-align: left;
    }

    .chat-msg.user {
      text-align: right;
    }

    .user-side,
    .ai-side {
      text-align: center;
    }

    .profile-box {
      border-radius: 10px;
      padding: 1rem;
      background: #e6f0ff;
    }

    .controls {
      display: flex;
      justify-content: center;
      gap: 1rem;
    }
  </style>
</head>
<body>

<div class="interview-room">
   <h2>AI Interview for {{ interview.candidate.username }}</h2>
  <h4 class="text-center mb-4">ü§ñ AI Interview for <span class="text-primary">{{ application.job.title }}</span></h4>

  <div class="row mb-4">
    <div class="col-md-6 user-side">
      <div class="profile-box">
        <h5>üë§ You</h5>
        <p>{% if request.user.is_authenticated %}{{ request.user.get_full_name }}{% else %}Guest User{% endif %}</p>

        
      </div>
    </div>
    <div class="col-md-6 ai-side">
      <div class="profile-box bg-light">
        <h5>ü§ñ AI Interviewer</h5>
        <p>Virtual HR Assistant</p>
      </div>
    </div>
  </div>

  <div class="chat-area" id="chatBox">
    <div class="chat-msg ai">
      <strong>AI:</strong>
      <span>{{ ai_question }}</span>
    </div>
  </div>

  <div class="controls">
    <button class="btn btn-success" id="startBtn">üéôÔ∏è Start Speaking</button>
    <button class="btn btn-danger" id="stopBtn">üõë Stop</button>
  </div>

 

  <audio controls autoplay muted class="mb-3 w-100" id="aiAudio">
    <source src="{{ audio_url }}" type="audio/mpeg">
  </audio>

  
</div>

<!-- Bootstrap JS -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>

<script>
  const startBtn = document.getElementById("startBtn");
  const stopBtn = document.getElementById("stopBtn");
  const chatBox = document.getElementById("chatBox");
  const aiAudio = document.getElementById("aiAudio");
  
  // Auto-start interview when page loads
  document.addEventListener('DOMContentLoaded', () => {
    setTimeout(() => {
      aiAudio.muted = false;
      aiAudio.play();
    }, 500);
  });
  
  // Unmute on any user interaction
  document.body.addEventListener('click', () => {
    aiAudio.muted = false;
    aiAudio.play();
  }, { once: true });

  let recognition;
  if ('webkitSpeechRecognition' in window) {
    recognition = new webkitSpeechRecognition();
    recognition.lang = "en-US";
    recognition.interimResults = false;

    //what happend when the user talk.
    recognition.onresult = function(event) {
      const userText = event.results[0][0].transcript;
      chatBox.innerHTML += `
        <div class="chat-msg user">
          <strong>You:</strong>
          <span>${userText}</span>
        </div>`;

      // ‚úÖ Speak the user's input aloud
      const synth = window.speechSynthesis;
      const utterance = new SpeechSynthesisUtterance(userText);
      utterance.lang = 'en-US';
      synth.speak(utterance);  

      fetch("", {
        method: "POST",
        headers: {
          'Content-Type': 'application/x-www-form-urlencoded',
          'X-CSRFToken': '{{ csrf_token }}'
        },
        body: new URLSearchParams({text: userText})
      })
      .then(res => res.json())
      .then(data => {
        chatBox.innerHTML += `
          <div class="chat-msg ai">
            <strong>AI:</strong>
            <span>${data.response}</span>
          </div>`;

        if (data.audio) {
          aiAudio.src = data.audio;
          aiAudio.muted = false;
          aiAudio.play();
        }
        chatBox.scrollTop = chatBox.scrollHeight;
      });
    };
  }  else {
    alert("Voice input not supported in your browser. Use Google Chrome.");
  }

  startBtn.onclick = () => {
    recognition && recognition.start();
  };
  stopBtn.onclick = () => recognition && recognition.stop();
</script>

</body>
</html> {% endcomment %}
