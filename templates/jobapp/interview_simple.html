{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Interview - {{ candidate_name }}</title>
    <link rel="stylesheet" href="{% static 'css/professional-interview.css' %}">
    <style>
        body {
            background: #202124;
            color: white;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            height: 100vh;
            overflow: hidden;
        }
        .container {
            max-width: 1400px;
            margin: 0 auto;
            height: calc(100vh - 40px);
            display: flex;
            flex-direction: column;
        }
        .video-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 20px;
        }
        .video-box {
            background: #303134;
            border-radius: 12px;
            height: 400px;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            border: 2px solid #444;
        }
        .candidate-box {
            height: 400px;
        }
        .ai-avatar {
            font-size: 80px;
            animation: pulse 2s ease-in-out infinite alternate;
        }
        .ai-speaking {
            animation: pulse 1s ease-in-out infinite alternate;
            border-color: #ff9800 !important;
            box-shadow: 0 0 20px rgba(255, 152, 0, 0.3);
        }
        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            border-radius: 12px;
        }
        .participant-name {
            position: absolute;
            bottom: 16px;
            left: 16px;
            background: rgba(0,0,0,0.8);
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 16px;
            font-weight: bold;
            backdrop-filter: blur(10px);
        }
        .controls {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            text-align: center;
            z-index: 1000;
            display: flex;
            gap: 15px;
        }
        .btn {
            background: #34a853;
            color: white;
            border: none;
            padding: 15px 20px;
            border-radius: 50px;
            font-size: 24px;
            cursor: pointer;
            transition: all 0.3s ease;
            min-width: 60px;
            height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .btn:hover {
            transform: scale(1.05);
            box-shadow: 0 4px 15px rgba(0,0,0,0.3);
        }
        .btn.recording {
            background: #ea4335;
            animation: recording-pulse 1s infinite;
        }
        .btn.camera-off {
            background: #ea4335;
        }
        .btn.disabled {
            background: #666;
            cursor: not-allowed;
            opacity: 0.5;
            pointer-events: none;
        }
        .btn.disabled:hover {
            transform: none;
            box-shadow: none;
        }
        .transcript-section {
            background: #303134;
            padding: 25px;
            border-radius: 12px;
            margin: 20px 0;
            flex: 1;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            border: 2px solid #444;
            min-height: 200px;
        }
        .conversation-text {
            background: transparent;
            padding: 20px;
            border-radius: 8px;
            color: white;
            font-size: 18px;
            line-height: 1.6;
            text-align: center;
            width: 100%;
            max-height: 200px;
            overflow-y: auto;
        }
        .stats {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
            padding: 0 10px;
        }
        .stat {
            background: #303134;
            padding: 12px 24px;
            border-radius: 25px;
            font-weight: 500;
            border: 2px solid #444;
        }
        .audio-status {
            position: fixed;
            top: 20px;
            left: 50%;
            transform: translateX(-50%);
            background: #1a73e8;
            color: white;
            padding: 12px 20px;
            border-radius: 25px;
            font-size: 14px;
            font-weight: 500;
            z-index: 1000;
            display: none;
            box-shadow: 0 4px 15px rgba(0,0,0,0.3);
            backdrop-filter: blur(10px);
        }
        .audio-status.playing {
            display: block;
            background: #ff9800;
            animation: status-pulse 2s ease-in-out infinite;
        }
        .audio-status.listening {
            display: block;
            background: #4caf50;
            animation: status-pulse 2s ease-in-out infinite;
        }
        
        /* Animations */
        @keyframes pulse {
            0%, 100% { opacity: 0.8; }
            50% { opacity: 1; }
        }
        @keyframes recording-pulse {
            0%, 100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(234, 67, 53, 0.7); }
            50% { transform: scale(1.05); box-shadow: 0 0 0 10px rgba(234, 67, 53, 0); }
        }
        @keyframes status-pulse {
            0%, 100% { opacity: 0.9; }
            50% { opacity: 1; }
        }
        
        /* Interview completion modal */
        .interview-complete-modal {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0,0,0,0.8);
            display: none;
            align-items: center;
            justify-content: center;
            z-index: 2000;
            backdrop-filter: blur(5px);
        }
        .modal-content {
            background: #303134;
            padding: 40px;
            border-radius: 20px;
            text-align: center;
            max-width: 500px;
            border: 2px solid #4caf50;
            animation: modal-appear 0.5s ease-out;
        }
        .modal-content h2 {
            color: #4caf50;
            margin-bottom: 20px;
            font-size: 28px;
        }
        .modal-content p {
            font-size: 18px;
            margin-bottom: 25px;
            line-height: 1.6;
        }
        .modal-btn {
            background: #4caf50;
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 25px;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        .modal-btn:hover {
            background: #45a049;
            transform: scale(1.05);
        }
        @keyframes modal-appear {
            0% { opacity: 0; transform: scale(0.7); }
            100% { opacity: 1; transform: scale(1); }
        }
        
        /* Connection status */
        .connection-status {
            position: fixed;
            top: 20px;
            right: 20px;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 12px;
            z-index: 1000;
        }
        .connection-status.connected {
            background: #4caf50;
            color: white;
        }
        .connection-status.disconnected {
            background: #f44336;
            color: white;
            animation: blink 1s infinite;
        }
        @keyframes blink {
            0%, 50% { opacity: 1; }
            51%, 100% { opacity: 0.5; }
        }

        /* Speech status indicator */
        .speech-status {
            position: fixed;
            bottom: 100px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(76, 175, 80, 0.9);
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 12px;
            display: none;
            z-index: 1000;
            backdrop-filter: blur(5px);
        }
        .speech-status.active {
            display: block;
            animation: pulse 2s infinite;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Audio status indicator -->
        <div class="audio-status" id="audioStatus"></div>
        
        <!-- Speech status indicator -->
        <div class="speech-status" id="speechStatus">ðŸŽ¤ Listening...</div>
        
        <!-- Connection status -->
        <div class="connection-status connected" id="connectionStatus">Connected</div>
        
        <div class="stats">
            <div class="stat">Question: <span id="questionCount">1/8</span></div>
            <div class="stat">Time: <span id="timer">15:00</span></div>
        </div>
        
        <div class="video-grid">
            <div class="video-box" id="aiVideoBox">
                <div class="ai-avatar" id="aiAvatar">ðŸ¤–</div>
                <div class="participant-name">Alex - AI Interviewer</div>
            </div>
            <div class="video-box candidate-box" id="candidateVideoBox">
                <video id="userVideo" autoplay muted playsinline></video>
                <div class="participant-name">{{ candidate_name|default:"Candidate" }}</div>
            </div>
        </div>

        <div class="transcript-section">
            <div class="conversation-text" id="conversationArea">
                Initializing interview system...
            </div>
        </div>

        <div class="controls">
            <button class="btn recording" id="micBtn" onclick="toggleMic()" title="Microphone is ON">ðŸŽ¤</button>
            <button class="btn" id="cameraBtn" onclick="toggleCamera()" title="Camera is ON">ðŸ“¹</button>
            <button class="btn" id="endBtn" onclick="endInterview()" title="End Interview" style="background: #ea4335;">ðŸ“ž</button>
        </div>
    </div>

    <!-- Interview completion modal -->
    <div class="interview-complete-modal" id="interviewCompleteModal">
        <div class="modal-content">
            <h2>Interview Complete!</h2>
            <p>Thank you for participating in the AI interview. Your responses have been recorded and will be reviewed by our team.</p>
            <p><strong>Next Steps:</strong> You will receive feedback within 2-3 business days via email.</p>
            <button class="modal-btn" onclick="goToDashboard()">Return to Dashboard</button>
        </div>
    </div>

    <!-- Audio element for interviewer questions -->
    <audio id="aiAudio" preload="auto"></audio>
    {% csrf_token %}
    
    <!-- Load typewriter before main script -->
    <script src="{% static 'js/typewriter-sync.js' %}"></script>

    <script>
    // Global variables
    let recognition = null;
    let isListening = false;
    let questionCount = 1;
    let timeLeft = 15 * 60; // 15 minutes
    let userStream = null;
    let isCameraOn = true;
    let collectedText = '';
    let speechTimeout = null;
    let lastSpeechTime = 0;
    let isProcessingResponse = false;
    let isInterviewerSpeaking = false;
    let interviewCompleted = false;
    let audioEndedTimeout = null;
    let currentAudioElement = null;
    let speechDetectionActive = false; // FIXED: Add proper speech detection state
    
    // Interview configuration
    const MAX_QUESTIONS = 8;
    const SPEECH_TIMEOUT_MS = 3000; // FIXED: Increased to 3 seconds for better speech capture
    
    console.log('AI Interview System Starting...');
    
    // Initialize camera and microphone
    async function initCamera() {
        try {
            console.log('Requesting camera and microphone permissions...');
            userStream = await navigator.mediaDevices.getUserMedia({ 
                video: {
                    width: { ideal: 1280 },
                    height: { ideal: 720 },
                    facingMode: 'user'
                }, 
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                    sampleRate: 44100
                }
            });
            
            const videoElement = document.getElementById('userVideo');
            videoElement.srcObject = userStream;
            console.log('Camera and microphone access granted');
            
            updateConnectionStatus(true);
            
        } catch (error) {
            console.error('Camera/Microphone error:', error);
            updateConnectionStatus(false);
            
            let message = 'Camera/Microphone Error: ';
            if (error.name === 'NotAllowedError') {
                message += 'Please allow camera and microphone access, then refresh this page.';
            } else if (error.name === 'NotFoundError') {
                message += 'No camera or microphone found. Please connect devices and refresh.';
            } else {
                message += 'Cannot access camera/microphone. Please check permissions and refresh.';
            }
            
            showError(message);
        }
    }
    
    // Update connection status indicator
    function updateConnectionStatus(connected) {
        const statusEl = document.getElementById('connectionStatus');
        if (connected) {
            statusEl.textContent = 'Connected';
            statusEl.className = 'connection-status connected';
        } else {
            statusEl.textContent = 'Connection Issues';
            statusEl.className = 'connection-status disconnected';
        }
    }
    
    // Show error message
    function showError(message) {
        document.getElementById('conversationArea').innerHTML = 
            `<div style="color: #f44336; background: rgba(244, 67, 54, 0.1); padding: 20px; border-radius: 10px; border: 1px solid #f44336;">
                <strong>Error:</strong> ${message}
            </div>`;
    }
    
    // FIXED: Update speech status indicator
    function updateSpeechStatus(isActive, message = '') {
        const speechStatus = document.getElementById('speechStatus');
        if (isActive && !isInterviewerSpeaking) {
            speechStatus.textContent = message || 'ðŸŽ¤ Listening...';
            speechStatus.classList.add('active');
        } else {
            speechStatus.classList.remove('active');
        }
    }
    
    // Toggle camera
    function toggleCamera() {
        if (!userStream) return;
        
        const videoTracks = userStream.getVideoTracks();
        isCameraOn = !isCameraOn;
        
        videoTracks.forEach(track => {
            track.enabled = isCameraOn;
        });
        
        const btn = document.getElementById('cameraBtn');
        const candidateBox = document.getElementById('candidateVideoBox');
        
        if (isCameraOn) {
            btn.innerHTML = 'ðŸ“¹';
            btn.classList.remove('camera-off');
            btn.title = 'Camera is ON';
            candidateBox.style.background = '#303134';
        } else {
            btn.innerHTML = 'ðŸ“¹';
            btn.classList.add('camera-off');
            btn.title = 'Camera is OFF';
            candidateBox.style.background = '#1a1a1a';
        }
        
        console.log(`Camera ${isCameraOn ? 'enabled' : 'disabled'}`);
    }
    
    // Enhanced audio playback control with proper TypewriterSync integration
    function showCurrentQuestion(question, audioUrl = null, audioDuration = null) {
        const element = document.getElementById('conversationArea');
        const audioStatus = document.getElementById('audioStatus');
        const micBtn = document.getElementById('micBtn');
        const aiVideoBox = document.getElementById('aiVideoBox');
        
        // Clear previous content and reset state
        element.innerHTML = '';
        isProcessingResponse = true;
        isInterviewerSpeaking = true; // FIXED: Set this immediately
        speechDetectionActive = false; // FIXED: Disable speech detection during AI speech
        
        // Update speech status
        updateSpeechStatus(false);
        
        // Clear any existing audio timeout
        if (audioEndedTimeout) {
            clearTimeout(audioEndedTimeout);
            audioEndedTimeout = null;
        }
        
        console.log('Showing AI question:', question.substring(0, 50) + '...');
        console.log('Audio URL:', audioUrl);
        console.log('Duration:', audioDuration);
        
        // Check if we have valid audio
        const hasValidAudio = audioUrl && audioUrl.trim() !== '' && audioUrl !== 'None' && audioDuration > 0;
        
        if (hasValidAudio) {
            console.log('Starting controlled audio playback');
            
            // Disable microphone and show visual feedback
            micBtn.classList.add('disabled');
            micBtn.title = 'Interviewer is speaking - Please listen';
            
            // Visual feedback
            aiVideoBox.classList.add('ai-speaking');
            audioStatus.className = 'audio-status playing';
            audioStatus.textContent = 'Interviewer speaking - Please listen carefully';
            audioStatus.style.display = 'block';
            
            // Setup audio element
            const audio = document.getElementById('aiAudio');
            currentAudioElement = audio;
            
            // Clear any previous audio
            audio.pause();
            audio.currentTime = 0;
            audio.src = audioUrl;
            audio.volume = 0.8;
            
            // Better audio event handling
            const onCanPlayThrough = () => {
                console.log('Audio ready to play');
                audio.removeEventListener('canplaythrough', onCanPlayThrough);
                
                audio.play().then(() => {
                    console.log('Audio playing - starting synchronized typewriter');
                    
                    // Use TypewriterSync with audio
                    if (window.TypewriterSync) {
                        window.TypewriterSync.start(element, question, audio, audioDuration);
                    } else {
                        console.warn('TypewriterSync not available, using fallback');
                        startFallbackTypewriter(element, question, audioDuration);
                    }
                    
                }).catch(error => {
                    console.error('Audio play failed:', error);
                    enableCandidateResponse('Audio playback failed');
                    startFallbackTypewriter(element, question);
                });
            };
            
            // Re-enable microphone when audio actually ends
            const onAudioEnded = () => {
                console.log('Audio playback ended - enabling candidate response');
                audio.removeEventListener('ended', onAudioEnded);
                enableCandidateResponse('Audio completed');
            };
            
            const onAudioError = (error) => {
                console.error('Audio error:', error);
                audio.removeEventListener('error', onAudioError);
                enableCandidateResponse('Audio error occurred');
                startFallbackTypewriter(element, question);
            };
            
            // Attach event listeners
            audio.addEventListener('canplaythrough', onCanPlayThrough);
            audio.addEventListener('ended', onAudioEnded);
            audio.addEventListener('error', onAudioError);
            
            // Backup timeout in case audio events don't fire
            audioEndedTimeout = setTimeout(() => {
                if (isInterviewerSpeaking) {
                    console.warn('Audio timeout reached - enabling microphone');
                    enableCandidateResponse('Audio timeout');
                }
            }, (audioDuration + 5) * 1000); // Extra 5 seconds buffer
            
            // Load audio
            try {
                audio.load();
            } catch (error) {
                console.error('Audio load failed:', error);
                enableCandidateResponse('Audio load failed');
                startFallbackTypewriter(element, question);
            }
            
        } else {
            console.log('No valid audio provided, using text-only typewriter');
            if (window.TypewriterSync) {
                window.TypewriterSync.createTextOnly(element, question, { fast: false }).then(() => {
                    setTimeout(() => enableCandidateResponse('Text completed'), 800);
                });
            } else {
                startFallbackTypewriter(element, question);
            }
        }
    }
    
    // Enhanced fallback typewriter
    function startFallbackTypewriter(element, question, audioDuration = null) {
        console.log('Using fallback typewriter');
        let index = 0;
        
        // Calculate typing speed based on audio duration or use default
        const targetDuration = audioDuration ? audioDuration * 1000 : Math.min(question.length * 60, 6000);
        const charDelay = Math.max(30, Math.min(100, targetDuration / question.length));
        
        const typeChar = () => {
            if (index < question.length) {
                element.textContent += question.charAt(index);
                index++;
                setTimeout(typeChar, charDelay);
            } else {
                // Typewriter finished, enable response after short delay
                setTimeout(() => {
                    enableCandidateResponse('Fallback typewriter completed');
                }, 800);
            }
        };
        typeChar();
    }
    
    // FIXED: Enable candidate response after audio completes
    function enableCandidateResponse(reason = 'Audio completed') {
        console.log('Enabling candidate response:', reason);
        
        isInterviewerSpeaking = false;
        isProcessingResponse = false;
        speechDetectionActive = true; // FIXED: Enable speech detection
        
        const micBtn = document.getElementById('micBtn');
        const audioStatus = document.getElementById('audioStatus');
        const aiVideoBox = document.getElementById('aiVideoBox');
        
        // Update UI elements
        micBtn.classList.remove('disabled');
        micBtn.title = 'Microphone is ON - Speak your answer';
        
        aiVideoBox.classList.remove('ai-speaking');
        
        audioStatus.className = 'audio-status listening';
        audioStatus.textContent = 'Your turn - Please speak your answer';
        
        // Update speech status
        updateSpeechStatus(true, 'ðŸŽ¤ Ready to listen - Please speak');
        
        // Hide status indicator after delay
        setTimeout(() => {
            if (audioStatus.style.display !== 'none') {
                audioStatus.style.display = 'none';
            }
        }, 4000);
        
        // Clear any audio timeout
        if (audioEndedTimeout) {
            clearTimeout(audioEndedTimeout);
            audioEndedTimeout = null;
        }
        
        // FIXED: Clear any collected text and reset speech state
        collectedText = '';
        if (speechTimeout) {
            clearTimeout(speechTimeout);
            speechTimeout = null;
        }
        
        console.log('Candidate can now respond - speech detection active');
    }
    
    // FIXED: Initialize speech recognition with better error handling
    function initSpeech() {
        if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
            console.error('Speech recognition not supported in this browser');
            showError('Speech recognition not supported. Please use Chrome, Edge, or Safari.');
            return;
        }
        
        const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
        recognition = new SpeechRecognition();
        
        // Configure speech recognition
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';
        recognition.maxAlternatives = 1;
        
        recognition.onstart = function() {
            isListening = true;
            document.getElementById('micBtn').classList.add('recording');
            document.getElementById('micBtn').innerHTML = 'ðŸ”´';
            console.log('Speech recognition started');
            
            // Update speech status if detection is active
            if (speechDetectionActive && !isInterviewerSpeaking) {
                updateSpeechStatus(true, 'ðŸŽ¤ Listening for your response...');
            }
        };
        
        recognition.onend = function() {
            console.log('Speech recognition ended, isListening:', isListening, 'completed:', interviewCompleted, 'interviewer speaking:', isInterviewerSpeaking);
            
            // Auto-restart if still supposed to be listening
            if (isListening && !interviewCompleted && !isInterviewerSpeaking) {
                setTimeout(() => {
                    try {
                        if (recognition && isListening && speechDetectionActive) {
                            recognition.start();
                            console.log('Speech recognition restarted');
                        }
                    } catch (e) {
                        console.warn('Could not restart recognition:', e.message);
                        if (e.name !== 'InvalidStateError') {
                            setTimeout(() => initSpeech(), 1000);
                        }
                    }
                }, 100);
            } else {
                // Clear UI states when not restarting
                document.getElementById('micBtn').classList.remove('recording');
                document.getElementById('micBtn').innerHTML = 'ðŸŽ¤';
                updateSpeechStatus(false);
            }
        };
        
        recognition.onerror = function(event) {
            console.error('Speech recognition error:', event.error);
            
            switch(event.error) {
                case 'not-allowed':
                    showError('Microphone access denied. Please allow microphone access and refresh the page.');
                    break;
                case 'no-speech':
                    console.log('No speech detected, continuing...');
                    // Don't show error for no speech - this is normal
                    break;
                case 'audio-capture':
                    showError('Microphone not available. Please check if another application is using it.');
                    break;
                case 'network':
                    console.log('Network error, attempting to restart...');
                    setTimeout(() => {
                        if (isListening && recognition && speechDetectionActive) {
                            try {
                                recognition.start();
                            } catch (e) {
                                console.log('Network restart failed');
                            }
                        }
                    }, 1000);
                    break;
                case 'aborted':
                    console.log('Speech recognition aborted - this is normal during transitions');
                    break;
                default:
                    console.warn('Unhandled speech error:', event.error);
            }
        };
        
        // FIXED: Improved speech result processing
        recognition.onresult = function(event) {
            // Only process if we're actively listening for candidate responses
            if (!speechDetectionActive || isInterviewerSpeaking || isProcessingResponse || interviewCompleted) {
                console.log('Ignoring speech - not ready for candidate input');
                return;
            }
            
            let interimTranscript = '';
            let finalTranscript = '';
            
            // Process all results
            for (let i = event.resultIndex; i < event.results.length; i++) {
                const transcript = event.results[i][0].transcript;
                if (event.results[i].isFinal) {
                    finalTranscript += transcript;
                } else {
                    interimTranscript += transcript;
                }
            }

            // Show real-time feedback
            const displayText = collectedText + finalTranscript + 
                (interimTranscript ? `<span style="opacity: 0.7; font-style: italic;">${interimTranscript}</span>` : '');
            
            if (displayText.trim()) {
                document.getElementById('conversationArea').innerHTML = displayText;
                updateSpeechStatus(true, 'ðŸŽ¤ Processing your speech...');
            }
        
            // Handle final transcript
            if (finalTranscript.trim()) {
                collectedText += finalTranscript;
                lastSpeechTime = Date.now();
                console.log('Speech collected:', collectedText.length, 'chars');
            
                // Clear existing timeout
                if (speechTimeout) {
                    clearTimeout(speechTimeout);
                }
            
                // FIXED: Auto-submit after speech pause with better timing
                speechTimeout = setTimeout(() => {
                    if (collectedText.trim() && speechDetectionActive && !isProcessingResponse && !isInterviewerSpeaking && !interviewCompleted) {
                        console.log('Auto-submitting response after speech pause:', collectedText.substring(0, 50) + '...');
                        autoSubmitResponse();
                    }
                }, SPEECH_TIMEOUT_MS);
                
                // Update status
                updateSpeechStatus(true, `ðŸŽ¤ Got ${collectedText.split(' ').length} words - keep speaking or wait 3 seconds to submit`);
            }
        };
        
        startMicrophone();
    }
    
    // Start microphone
    function startMicrophone() {
        if (recognition && !isListening && !interviewCompleted) {
            try {
                isListening = true;
                recognition.start();
                console.log('Microphone started successfully');
            } catch (e) {
                console.error('Failed to start microphone:', e);
                if (e.name === 'InvalidStateError') {
                    console.log('Recognition already running, continuing...');
                    isListening = true;
                } else {
                    isListening = false;
                }
            }
        }
    }
    
            // FIXED: Auto-submit collected speech with proper state management
    function autoSubmitResponse() {
        if (isProcessingResponse || isInterviewerSpeaking || !collectedText.trim() || interviewCompleted || !speechDetectionActive) {
            console.log('Skipping auto-submit - conditions not met');
            return;
        }
        
        console.log('Auto-submitting response:', collectedText.substring(0, 100) + '...');
        
        // FIXED: Set processing state and disable speech detection
        isProcessingResponse = true;
        speechDetectionActive = false;
        
        // Update UI to show processing
        updateSpeechStatus(false);
        
        // Clear speech timeout
        if (speechTimeout) {
            clearTimeout(speechTimeout);
            speechTimeout = null;
        }
        
        const responseText = collectedText.trim();
        collectedText = ''; // Clear collected text
        
        // Show processing state
        document.getElementById('conversationArea').innerHTML = 
            `<div style="opacity: 0.7; font-style: italic;">Processing your response: "${responseText.substring(0, 50)}${responseText.length > 50 ? '...' : ''}"</div>`;
        
        sendResponse(responseText).finally(() => {
            isProcessingResponse = false;
            console.log('Response processing complete');
        });
    }
    
    // FIXED: Send response to server with improved error handling and proper state management
    async function sendResponse(text) {
        try {
            console.log('Sending response to server:', text.substring(0, 100) + '...');
            
            updateConnectionStatus(true);
            
            const response = await fetch(window.location.href, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/x-www-form-urlencoded',
                    'X-CSRFToken': document.querySelector('[name=csrfmiddlewaretoken]').value,
                },
                body: new URLSearchParams({ text: text })
            });
            
            if (!response.ok) {
                throw new Error(`Server responded with ${response.status}: ${response.statusText}`);
            }
            
            const data = await response.json();
            console.log('Server response received:', data);
            
            if (data.success) {
                console.log('Response processed successfully');
                
                // Update question count
                questionCount = data.question_count || questionCount + 1;
                document.getElementById('questionCount').textContent = `${questionCount}/${MAX_QUESTIONS}`;
                
                // Clear conversation area before showing new question
                document.getElementById('conversationArea').innerHTML = '';
                
                // Small delay before showing next question for better UX
                setTimeout(() => {
                    showCurrentQuestion(data.response, data.audio, data.audio_duration);
                }, 500);
                
                // Check if interview is complete
                if (data.is_final || questionCount >= MAX_QUESTIONS) {
                    console.log('Interview completed, scheduling completion...');
                    setTimeout(() => {
                        completeInterview();
                    }, (data.audio_duration || 5) * 1000 + 3000); // Wait for audio + buffer
                }
            } else {
                console.error('Server returned error:', data);
                showError('Could not process your response. Please try speaking again.');
                enableCandidateResponse('Server error');
            }
        } catch (error) {
            console.error('Network error:', error);
            updateConnectionStatus(false);
            showError('Network error. Please check your connection and try again.');
            enableCandidateResponse('Network error');
        }
    }
    
    // Complete interview
    function completeInterview() {
        console.log('Completing interview...');
        
        interviewCompleted = true;
        speechDetectionActive = false; // FIXED: Disable speech detection
        
        // Stop speech recognition
        if (recognition && isListening) {
            isListening = false;
            try {
                recognition.stop();
            } catch (e) {
                console.log('Speech recognition already stopped');
            }
        }
        
        // Stop any playing audio
        if (currentAudioElement) {
            currentAudioElement.pause();
            currentAudioElement.currentTime = 0;
        }
        
        // Update UI
        document.getElementById('audioStatus').style.display = 'none';
        updateSpeechStatus(false);
        
        // Disable controls
        const controls = document.querySelectorAll('.btn');
        controls.forEach(btn => {
            btn.classList.add('disabled');
        });
        
        // Show completion modal
        setTimeout(() => {
            document.getElementById('interviewCompleteModal').style.display = 'flex';
        }, 1000);
    }
    
    // FIXED: Toggle microphone with proper state management
    function toggleMic() {
        if (!recognition || interviewCompleted) return;
        
        // Prevent toggling when interviewer is speaking
        if (isInterviewerSpeaking) {
            alert('Please wait for the interviewer to finish speaking.');
            return;
        }
        
        if (isListening) {
            // Turn off microphone
            if (confirm('Turn off microphone? This is not recommended during the interview.')) {
                isListening = false;
                speechDetectionActive = false;
                try {
                    recognition.stop();
                } catch (e) {
                    console.log('Recognition stop error:', e);
                }
                document.getElementById('micBtn').classList.remove('recording');
                document.getElementById('micBtn').innerHTML = 'ðŸŽ¤';
                updateSpeechStatus(false);
                
                // Submit any collected text
                if (speechTimeout) {
                    clearTimeout(speechTimeout);
                    speechTimeout = null;
                }
                
                if (collectedText.trim()) {
                    autoSubmitResponse();
                }
            }
        } else {
            // Turn on microphone
            isListening = true;
            speechDetectionActive = true;
            collectedText = '';
            try {
                recognition.start();
                updateSpeechStatus(true, 'ðŸŽ¤ Microphone enabled - Ready to listen');
            } catch (e) {
                console.error('Failed to restart microphone:', e);
                isListening = false;
                speechDetectionActive = false;
            }
        }
    }
    
    // Timer functionality
    function updateTimer() {
        if (interviewCompleted) return;
        
        const minutes = Math.floor(timeLeft / 60);
        const seconds = timeLeft % 60;
        document.getElementById('timer').textContent = 
            `${minutes}:${seconds.toString().padStart(2, '0')}`;
        
        if (timeLeft <= 0) {
            console.log('Time expired - ending interview');
            completeInterview();
            return;
        }
        
        timeLeft--;
    }
    
    // End interview manually
    function endInterview() {
        if (confirm('Are you sure you want to end the interview? This action cannot be undone.')) {
            console.log('Interview ended manually');
            completeInterview();
        }
    }
    
    // Go to dashboard
    function goToDashboard() {
        console.log('Redirecting to dashboard');
        window.location.href = '{% url "jobseeker_dashboard" %}';
    }
    
    // FIXED: Initialize everything when page loads with proper sequencing
    document.addEventListener('DOMContentLoaded', function() {
        console.log('AI Interview System Starting...');
        
        // Initialize camera and microphone
        initCamera();
        
        // Initialize speech recognition after delay
        setTimeout(() => {
            initSpeech();
        }, 1000);
        
        // Start timer
        const timerInterval = setInterval(() => {
            updateTimer();
            if (interviewCompleted) {
                clearInterval(timerInterval);
            }
        }, 1000);
        
        // Get initial question data from template
        const initialQuestion = `{{ ai_question|escapejs|default:"Welcome to your AI interview! Let's begin." }}`;
        const initialAudio = `{{ audio_url|escapejs|safe }}`;
        const initialDuration = {{ audio_duration|default:"5" }};
        
        console.log('Initial question prepared');
        console.log('Audio URL:', initialAudio);
        console.log('Duration:', initialDuration, 'seconds');
        
        // Show initial question after short delay
        setTimeout(() => {
            showCurrentQuestion(initialQuestion, initialAudio, initialDuration);
            console.log('Interview started successfully');
        }, 1500);
        
        // Prevent page refresh during interview
        window.addEventListener('beforeunload', function(e) {
            if (!interviewCompleted) {
                e.preventDefault();
                e.returnValue = 'Interview is in progress. Are you sure you want to leave?';
                return e.returnValue;
            }
        });
        
        console.log('AI Interview System initialized successfully');
    });
    
    // FIXED: Add keyboard shortcut for manual submission (spacebar)
    document.addEventListener('keydown', function(e) {
        // Allow spacebar to manually submit response when candidate can speak
        if (e.code === 'Space' && speechDetectionActive && !isInterviewerSpeaking && !isProcessingResponse && collectedText.trim()) {
            e.preventDefault();
            console.log('Manual submission via spacebar');
            autoSubmitResponse();
        }
    });
</script>
</body>
</html>