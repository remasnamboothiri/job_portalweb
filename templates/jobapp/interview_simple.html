{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Interview</title>
    <link rel="stylesheet" href="{% static 'css/professional-interview.css' %}">
    <style>
        body {
            background: #202124;
            color: white;
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            height: 100vh;
            overflow: hidden;
        }
        .container {
            max-width: 1400px;
            margin: 0 auto;
            height: calc(100vh - 40px);
            display: flex;
            flex-direction: column;
        }
        .video-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 20px;
        }
        .video-box {
            background: #303134;
            border-radius: 12px;
            height: 400px;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
        }
        .candidate-box {
            height: 400px;
        }
        .ai-avatar {
            font-size: 80px;
        }
        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            border-radius: 12px;
        }
        .participant-name {
            position: absolute;
            bottom: 16px;
            left: 16px;
            background: rgba(0,0,0,0.8);
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 16px;
            font-weight: bold;
        }
        .controls {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            text-align: center;
            z-index: 1000;
        }
        .btn {
            background: #34a853;
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 25px;
            font-size: 16px;
            cursor: pointer;
            margin: 0 10px;
        }
        .btn:hover {
            opacity: 0.8;
        }
        .btn.recording {
            background: #ea4335;
            animation: pulse 1s infinite;
        }
        .btn.camera-off {
            background: #ea4335;
        }
        .btn.disabled {
            background: #666;
            cursor: not-allowed;
            opacity: 0.5;
        }
        .transcript-section {
            background: #303134;
            padding: 20px;
            border-radius: 12px;
            margin: 20px 0;
            flex: 1;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
        }
        .conversation-text {
            background: transparent;
            padding: 20px;
            border-radius: 8px;
            color: white;
            font-size: 18px;
            line-height: 1.6;
            text-align: center;
            width: 100%;
        }
        .transcript-item {
            margin: 10px 0;
            padding: 10px;
            border-radius: 8px;
        }
        .interviewer-msg {
            background: #1a73e8;
            text-align: left;
        }
        .candidate-msg {
            background: #34a853;
            text-align: right;
        }
        .stats {
            display: flex;
            justify-content: space-between;
            margin-bottom: 20px;
        }
        .stat {
            background: #303134;
            padding: 10px 20px;
            border-radius: 20px;
        }
        .audio-status {
            position: fixed;
            top: 20px;
            left: 50%;
            transform: translateX(-50%);
            background: #1a73e8;
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 12px;
            z-index: 1000;
            display: none;
        }
        .audio-status.playing {
            display: block;
            background: #ff9800;
        }
        .audio-status.listening {
            display: block;
            background: #4caf50;
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Audio status indicator -->
        <div class="audio-status" id="audioStatus">
            Interviewer speaking - Please listen
        </div>
        
        <div class="stats">
            <div class="stat">Question: <span id="questionCount">1/8</span></div>
            <div class="stat">Time: <span id="timer">15:00</span></div>
        </div>
        
        <!-- Audio Level Indicator -->
        <div class="audio-level-indicator" id="audioLevelIndicator">
            <div class="audio-level-bar"></div>
            <div class="audio-level-bar"></div>
            <div class="audio-level-bar"></div>
            <div class="audio-level-bar"></div>
            <div class="audio-level-bar"></div>
        </div>
        
        <div class="video-grid">
            <div class="video-box">
                <div class="ai-avatar">ü§ñ</div>
                <div class="participant-name">Alex - AI Interviewer</div>
            </div>
            <div class="video-box candidate-box recording">
                <video id="userVideo" autoplay muted playsinline></video>
                <div class="participant-name">{{ candidate_name|default:"Candidate" }}</div>
            </div>
        </div>

        <div class="transcript-section">
            <div class="conversation-text" id="conversationArea">
                
            </div>
        </div>

        <div class="controls">
            <button class="btn recording" id="micBtn" onclick="toggleMic()" title="Microphone is ON">üî¥ </button>
            <button class="btn" id="cameraBtn" onclick="toggleCamera()">üìπ </button>
            <button class="btn" id="endBtn" onclick="endInterview()" style="background: #ea4335;">üìû </button>
        </div>
    </div>

    <!-- Audio element for interviewer questions -->
    <audio id="aiAudio" preload="auto"></audio>
    {% csrf_token %}
    
    <script src="{% static 'js/typewriter-sync.js' %}"></script>

    <script>
    let recognition = null;
    let isListening = false;
    let questionCount = 1;
    let timeLeft = 15 * 60;
    let userStream = null;
    let isCameraOn = true;
    let collectedText = '';
    let speechTimeout = null;
    let lastSpeechTime = 0;
    let isProcessingResponse = false;
    let isInterviewerSpeaking = false;  // NEW: Track when interviewer is speaking
    
    // Initialize camera and microphone
    async function initCamera() {
        try {
            console.log('üéôÔ∏è Requesting microphone and camera permissions...');
            userStream = await navigator.mediaDevices.getUserMedia({ 
                video: true, 
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                    sampleRate: 44100
                }
            });
            
            const videoElement = document.getElementById('userVideo');
            videoElement.srcObject = userStream;
            console.log('‚úÖ Camera and microphone access granted');
            
        } catch (error) {
            console.error('‚ùå Camera/Microphone error:', error);
            let message = '';
            if (error.name === 'NotAllowedError') {
                message = 'Please allow microphone and camera access in your browser, then refresh this page.';
            } else if (error.name === 'NotFoundError') {
                message = 'No microphone found. Please connect a microphone and refresh this page.';
            } else {
                message = 'Cannot access microphone. Please check your browser permissions and refresh this page.';
            }
            alert('Microphone Error: ' + message);
        }
    }
    
    // Toggle camera
    function toggleCamera() {
        if (!userStream) return;
        
        const videoTracks = userStream.getVideoTracks();
        isCameraOn = !isCameraOn;
        
        videoTracks.forEach(track => {
            track.enabled = isCameraOn;
        });
        
        const btn = document.getElementById('cameraBtn');
        if (isCameraOn) {
            btn.innerHTML = 'üìπ';
            btn.classList.remove('camera-off');
        } else {
            btn.innerHTML = 'üìπ';
            btn.classList.add('camera-off');
        }
    }
    
    // FIXED: Show current question with controlled audio playback
    function showCurrentQuestion(question, audioUrl = null, audioDuration = null) {
        const element = document.getElementById('conversationArea');
        const audioStatus = document.getElementById('audioStatus');
        const micBtn = document.getElementById('micBtn');
        
        element.innerHTML = '';
        isProcessingResponse = true;
        
        console.log('üìù Showing AI question with controlled audio:', question.substring(0, 50) + '...');
        
        if (audioUrl && audioUrl.trim() !== '' && audioUrl !== 'None') {
            console.log('üîä Starting controlled audio playback');
            
            // CRITICAL: Disable microphone during audio playback
            isInterviewerSpeaking = true;
            micBtn.classList.add('disabled');
            micBtn.title = 'Listening to interviewer - microphone temporarily disabled';
            
            audioStatus.className = 'audio-status playing';
            audioStatus.textContent = 'Interviewer speaking - Please listen';
            
            const audio = document.getElementById('aiAudio');
            audio.src = audioUrl;
            audio.volume = 0.8;
            
            // Start typewriter synchronized with audio
            const totalChars = question.length;
            const audioDurationMs = (audioDuration || 5) * 1000;
            const charDelay = Math.max(30, audioDurationMs / totalChars);
            
            let index = 0;
            const streamText = () => {
                if (index < question.length) {
                    element.innerHTML += question.charAt(index);
                    index++;
                    setTimeout(streamText, charDelay);
                }
            };
            
            audio.oncanplaythrough = () => {
                audio.play().then(() => {
                    console.log('üîä Audio playing - microphone disabled');
                    streamText(); // Start typewriter with audio
                }).catch(error => {
                    console.error('Audio play failed:', error);
                    enableCandidateResponse();
                    startFallbackTypewriter(element, question);
                });
            };
            
            // CRITICAL: Re-enable microphone when audio ends
            audio.onended = () => {
                console.log('‚úÖ Audio ended - enabling candidate microphone');
                enableCandidateResponse();
            };
            
            audio.onerror = (error) => {
                console.error('Audio error:', error);
                enableCandidateResponse();
                startFallbackTypewriter(element, question);
            };
            
            // Fallback if audio doesn't load
            setTimeout(() => {
                if (isInterviewerSpeaking) {
                    console.warn('Audio timeout - enabling microphone anyway');
                    enableCandidateResponse();
                }
            }, (audioDuration + 3) * 1000);
            
            try {
                audio.load();
            } catch (error) {
                console.error('Audio load failed:', error);
                enableCandidateResponse();
                startFallbackTypewriter(element, question);
            }
            
        } else {
            console.log('üñäÔ∏è No audio, using fast typewriter');
            startFallbackTypewriter(element, question);
        }
    }
    
    // Enable candidate response after audio ends
    function enableCandidateResponse() {
        isInterviewerSpeaking = false;
        isProcessingResponse = false;
        
        const micBtn = document.getElementById('micBtn');
        const audioStatus = document.getElementById('audioStatus');
        
        micBtn.classList.remove('disabled');
        micBtn.title = 'Microphone is ON - You can speak now';
        
        audioStatus.className = 'audio-status listening';
        audioStatus.textContent = 'Your turn - Please speak your answer';
        
        // Hide status after 3 seconds
        setTimeout(() => {
            audioStatus.style.display = 'none';
        }, 3000);
        
        console.log('‚úÖ Candidate can now respond');
    }
    
    // Fallback typewriter without audio
    function startFallbackTypewriter(element, question) {
        let index = 0;
        const streamText = () => {
            if (index < question.length) {
                element.innerHTML += question.charAt(index);
                index++;
                setTimeout(streamText, 50);
            } else {
                // Typewriter finished, enable candidate response
                setTimeout(() => {
                    enableCandidateResponse();
                }, 500);
            }
        };
        streamText();
    }
    
    // Initialize speech recognition with controlled flow
    function initSpeech() {
        if (!('webkitSpeechRecognition' in window)) {
            console.error('‚ùå Speech recognition not supported');
            alert('Speech recognition not supported in this browser. Please use Chrome or Edge.');
            return;
        }
        
        recognition = new webkitSpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';
        
        recognition.onstart = function() {
            isListening = true;
            document.getElementById('micBtn').classList.add('recording');
            document.getElementById('micBtn').innerHTML = 'üî¥';
            console.log('üéôÔ∏è Microphone started');
        };
        
        recognition.onend = function() {
            console.log('üéôÔ∏è Speech recognition ended - auto-restarting');
            if (isListening) {
                setTimeout(() => {
                    try {
                        recognition.start();
                        console.log('üîÑ Microphone restarted');
                    } catch (e) {
                        console.log('‚ùå Recognition restart failed:', e);
                    }
                }, 50);
            }
        };
        
        recognition.onerror = function(event) {
            console.error('‚ùå Speech recognition error:', event.error);
            
            switch(event.error) {
                case 'not-allowed':
                    alert('Microphone permission required for interview. Please allow microphone access and refresh the page.');
                    break;
                case 'no-speech':
                    break;
                case 'audio-capture':
                    alert('Cannot capture audio from microphone. Please check if another application is using your microphone.');
                    break;
                case 'network':
                    console.log('üåê Network error, retrying...');
                    setTimeout(() => {
                        if (isListening) {
                            try {
                                recognition.start();
                            } catch (e) {
                                console.log('‚ùå Network retry failed:', e);
                            }
                        }
                    }, 100);
                    break;
            }
        };
        
        recognition.onresult = function(event) {
            let interimTranscript = '';
            let finalTranscript = '';
            
            for (let i = event.resultIndex; i < event.results.length; i++) {
                if (event.results[i].isFinal) {
                    finalTranscript += event.results[i][0].transcript;
                } else {
                    interimTranscript += event.results[i][0].transcript;
                }
            }

            // CRITICAL: Only process speech when interviewer is NOT speaking
            if (!isInterviewerSpeaking && !isProcessingResponse) {
                const displayText = collectedText + finalTranscript + interimTranscript;
                if (displayText.trim()) {
                    document.getElementById('conversationArea').innerHTML = displayText;
                    console.log('üë§ Candidate speaking:', displayText.substring(0, 50) + '...');
                }
            
                if (finalTranscript.trim()) {
                    collectedText += finalTranscript;
                    lastSpeechTime = Date.now();
                    console.log('‚úÖ Speech collected:', collectedText.substring(0, 50) + '...');
                
                    if (speechTimeout) {
                        clearTimeout(speechTimeout);
                    }
                
                    // Auto-submit after pause
                    speechTimeout = setTimeout(() => {
                        if (collectedText.trim() && !isProcessingResponse && !isInterviewerSpeaking) {
                            console.log('‚ö° Auto-submitting response');
                            autoSubmitResponse();
                        }
                    }, 2000); // 2 second pause
                }
            } else {
                // Log but ignore speech while interviewer is speaking
                if (isInterviewerSpeaking) {
                    console.log('üö´ Ignoring candidate speech - interviewer is speaking');
                }
            }
        };
        
        startMicrophone();
    }
    
    // Start microphone
    function startMicrophone() {
        if (recognition && !isListening) {
            try {
                isListening = true;
                recognition.start();
                console.log('üéôÔ∏è Microphone started');
            } catch (e) {
                console.error('‚ùå Failed to start microphone:', e);
            }
        }
    }
    
    // Auto-submit response
    function autoSubmitResponse() {
        if (isProcessingResponse || isInterviewerSpeaking || !collectedText.trim()) return;
        
        console.log('üì§ Auto-submitting response');
        isProcessingResponse = true;
        
        if (speechTimeout) {
            clearTimeout(speechTimeout);
            speechTimeout = null;
        }
        
        const responseText = collectedText.trim();
        collectedText = '';
        
        sendResponse(responseText).finally(() => {
            isProcessingResponse = false;
            console.log('‚úÖ Processing complete');
        });
    }
    
    // Send response to server
    async function sendResponse(text) {
        try {
            console.log('‚ö° Sending candidate response:', text);
            
            const response = await fetch(window.location.href, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/x-www-form-urlencoded',
                    'X-CSRFToken': document.querySelector('[name=csrfmiddlewaretoken]').value,
                },
                body: new URLSearchParams({ text: text })
            });
            
            console.log('‚ö° Server response status:', response.status);
            const data = await response.json();
            console.log('‚ö° Server response data:', data);
            
            if (data.success) {
                console.log('‚ö° Response processed, showing AI question');
                
                document.getElementById('conversationArea').innerHTML = '';
                
                // Small delay before showing next question
                setTimeout(() => {
                    showCurrentQuestion(data.response, data.audio, data.audio_duration);
                }, 200);
                
                questionCount = data.question_count || questionCount + 1;
                document.getElementById('questionCount').textContent = questionCount + '/8';
                
                if (data.is_final || questionCount >= 8) {
                    setTimeout(endInterview, 5000);
                }
            } else {
                console.error('‚ùå Server returned error:', data);
                alert('Error: Could not process your response. Please try again.');
            }
        } catch (error) {
            console.error('‚ùå Network error:', error);
            alert('Network error. Please check your connection and try again.');
        }
    }
    
    // Toggle microphone
    function toggleMic() {
        if (!recognition) return;
        
        // Don't allow toggling when interviewer is speaking
        if (isInterviewerSpeaking) {
            alert('Please wait for the interviewer to finish speaking before toggling microphone.');
            return;
        }
        
        if (isListening) {
            if (confirm('Turn off microphone? This is not recommended during interview.')) {
                isListening = false;
                recognition.stop();
                document.getElementById('micBtn').classList.remove('recording');
                document.getElementById('micBtn').innerHTML = 'üé§';
                
                if (speechTimeout) {
                    clearTimeout(speechTimeout);
                    speechTimeout = null;
                }
                
                if (collectedText.trim()) {
                    sendResponse(collectedText.trim());
                    collectedText = '';
                }
            }
        } else {
            isListening = true;
            collectedText = '';
            try {
                recognition.start();
            } catch (e) {
                console.log('‚ùå Failed to restart microphone:', e);
            }
        }
    }
    
    // Timer
    function updateTimer() {
        const minutes = Math.floor(timeLeft / 60);
        const seconds = timeLeft % 60;
        document.getElementById('timer').textContent = 
            minutes + ':' + seconds.toString().padStart(2, '0');
        
        if (timeLeft <= 0) {
            endInterview();
            return;
        }
        timeLeft--;
    }
    
    // End interview
    function endInterview() {
        if (recognition && isListening) {
            isListening = false;
            recognition.stop();
        }
        alert('Interview completed! Redirecting to dashboard...');
        window.location.href = '{% url "jobseeker_dashboard" %}';
    }
    
    // Initialize everything
    document.addEventListener('DOMContentLoaded', function() {
        console.log('üöÄ Interview system initializing with controlled audio...');
        
        initCamera();
        initSpeech();
        setInterval(updateTimer, 1000);
        
        // Get initial question data
        const initialQuestion = `{{ ai_question|escapejs|default:"Hello! Welcome to your AI interview. Can you tell me about yourself?" }}`;
        const initialAudio = `{{ audio_url|escapejs|safe }}`;
        const initialDuration = {{ audio_duration|default:"5" }};
        
        console.log('üìù Initial question:', initialQuestion.substring(0, 50) + '...');
        console.log('üîä Initial audio:', initialAudio);
        console.log('‚è±Ô∏è Initial duration:', initialDuration);
        
        // Show initial question with audio after short delay
        setTimeout(() => {
            showCurrentQuestion(initialQuestion, initialAudio, initialDuration);
            console.log('‚úÖ Initial question started with controlled audio');
        }, 1000);
        
        console.log('‚úÖ Interview system ready with audio feedback prevention');
    });
</script>
</body>
</html>