{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Interview</title>
    <link rel="stylesheet" href="{% static 'css/professional-interview.css' %}">
    <style>
        body {
            background: #202124;
            color: white;
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            height: 100vh;
            overflow: hidden;
        }
        .container {
            max-width: 1400px;
            margin: 0 auto;
            height: calc(100vh - 40px);
            display: flex;
            flex-direction: column;
        }
        .video-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 20px;
        }
        .video-box {
            background: #303134;
            border-radius: 12px;
            height: 400px;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
        }
        .candidate-box {
            height: 400px;
        }
        .ai-avatar {
            font-size: 80px;
        }
        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            border-radius: 12px;
        }
        .participant-name {
            position: absolute;
            bottom: 16px;
            left: 16px;
            background: rgba(0,0,0,0.8);
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 16px;
            font-weight: bold;
        }
        .controls {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            text-align: center;
            z-index: 1000;
        }
        .btn {
            background: #34a853;
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 25px;
            font-size: 16px;
            cursor: pointer;
            margin: 0 10px;
        }
        .btn:hover {
            opacity: 0.8;
        }
        .btn.recording {
            background: #ea4335;
            animation: pulse 1s infinite;
        }
        .btn.camera-off {
            background: #ea4335;
        }
        .transcript-section {
            background: #303134;
            padding: 20px;
            border-radius: 12px;
            margin: 20px 0;
            flex: 1;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
        }
        .conversation-text {
            background: transparent;
            padding: 20px;
            border-radius: 8px;
            color: white;
            font-size: 18px;
            line-height: 1.6;
            text-align: center;
            width: 100%;
        }
        .transcript-item {
            margin: 10px 0;
            padding: 10px;
            border-radius: 8px;
        }
        .interviewer-msg {
            background: #1a73e8;
            text-align: left;
        }
        .candidate-msg {
            background: #34a853;
            text-align: right;
        }
        .stats {
            display: flex;
            justify-content: space-between;
            margin-bottom: 20px;
        }
        .stat {
            background: #303134;
            padding: 10px 20px;
            border-radius: 20px;
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="stats">
            <div class="stat">Question: <span id="questionCount">1/8</span></div>
            <div class="stat">Time: <span id="timer">15:00</span></div>
        </div>
        
        <!-- Professional Interview Status Indicator -->
        <div class="interview-status recording" id="interviewStatus">
            <div class="status-dot"></div>
            
        </div>
        
        <!-- Audio Level Indicator -->
        <div class="audio-level-indicator" id="audioLevelIndicator">
            <div class="audio-level-bar"></div>
            <div class="audio-level-bar"></div>
            <div class="audio-level-bar"></div>
            <div class="audio-level-bar"></div>
            <div class="audio-level-bar"></div>
        </div>
        
        <div class="video-grid">
            <div class="video-box">
                <div class="ai-avatar">ðŸ¤–</div>
                <div class="participant-name">Alex - AI Interviewer</div>
            </div>
            <div class="video-box candidate-box recording">
                <video id="userVideo" autoplay muted playsinline></video>
                <div class="participant-name">{{ candidate_name|default:"Candidate" }}</div>
            </div>
        </div>
        
        <div class="transcript-section">
            <div class="conversation-text" id="conversationArea">
            </div>
        </div>
        
        <div class="controls">
            <button class="btn recording" id="micBtn" onclick="toggleMic()" title="Microphone is ON (Professional Interview Mode)">ðŸ”´ </button>
            <button class="btn" id="cameraBtn" onclick="toggleCamera()">ðŸ“¹ </button>
            <button class="btn" id="endBtn" onclick="endInterview()" style="background: #ea4335;">ðŸ“ž </button>
        </div>
    </div>

    <audio id="aiAudio" preload="auto"></audio>
    {% csrf_token %}
    
    <!-- Professional Interview Audio System -->
    <!-- Load TypewriterSync for better synchronization -->
    <script src="{% static 'js/typewriter-sync.js' %}"></script>
    <script src="{% static 'js/professional-interview-audio.js' %}"></script>

    <script>
        let recognition = null;
        let isListening = false;
        let questionCount = 1;
        let timeLeft = 15 * 60;
        let userStream = null;
        let isCameraOn = true;
        let audioContext = null;
        let microphoneSource = null;
        let echoCancellation = null;
        
        // Initialize camera with audio isolation
        async function initCamera() {
            try {
                // Request media with echo cancellation and noise suppression
                userStream = await navigator.mediaDevices.getUserMedia({ 
                    video: true, 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleRate: 44100
                    }
                });
                
                const videoElement = document.getElementById('userVideo');
                videoElement.srcObject = userStream;
                
                // Setup audio isolation to prevent feedback
                setupAudioIsolation();
                
            } catch (error) {
                console.error('Camera error:', error);
            }
        }
        
        // Setup audio isolation to prevent speaker feedback
        function setupAudioIsolation() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                // Create microphone source
                microphoneSource = audioContext.createMediaStreamSource(userStream);
                
                // Create gain node for volume control
                const gainNode = audioContext.createGain();
                gainNode.gain.value = 1.0;
                
                // Connect microphone to gain node
                microphoneSource.connect(gainNode);
                
                console.log('Audio isolation setup complete');
            } catch (error) {
                console.error('Audio isolation setup failed:', error);
            }
        }
        
        // Toggle camera
        function toggleCamera() {
            if (!userStream) return;
            
            const videoTracks = userStream.getVideoTracks();
            isCameraOn = !isCameraOn;
            
            videoTracks.forEach(track => {
                track.enabled = isCameraOn;
            });
            
            const btn = document.getElementById('cameraBtn');
            if (isCameraOn) {
                btn.innerHTML = 'ðŸ“¹';
                btn.classList.remove('camera-off');
            } else {
                btn.innerHTML = 'ðŸ“¹';
                btn.classList.add('camera-off');
            }
        }
        
        // Interactive conversation system - AI stops when candidate speaks
        let currentTypewriterInterval = null;
        let currentAudioElement = null;
        let isAISpeaking = false;
        
        function showCurrentQuestion(question, audioUrl = null, audioDuration = null) {
            const element = document.getElementById('conversationArea');
            element.innerHTML = '';
            
            // Clear any previous typewriter
            if (currentTypewriterInterval) {
                clearInterval(currentTypewriterInterval);
                currentTypewriterInterval = null;
            }
            
            if (audioUrl && audioUrl.trim() !== '' && audioUrl !== 'None') {
                console.log('ðŸ—£ï¸ INTERACTIVE: Starting AI question with interruption support');
                
                const audio = document.getElementById('aiAudio');
                audio.src = audioUrl;
                audio.volume = 0.7;
                currentAudioElement = audio;
                
                audio.oncanplaythrough = () => {
                    console.log('ðŸ—£ï¸ INTERACTIVE: Audio ready, starting interruptible conversation');
                    
                    // Start audio
                    audio.play().then(() => {
                        isAISpeaking = true;
                        console.log('ðŸ—£ï¸ AI SPEAKING: Now listening for interruptions');
                        
                        // Start interruptible typewriter
                        startInterruptibleTypewriter(element, question, audioDuration || audio.duration || 5);
                        
                        // Setup interruption detection
                        setupInterruptionDetection();
                        
                    }).catch(error => {
                        console.error('INTERACTIVE: Audio play failed:', error);
                        startNaturalTypewriter(element, question);
                    });
                };
                
                audio.onended = () => {
                    isAISpeaking = false;
                    console.log('ðŸ—£ï¸ AI FINISHED: Question complete, ready for response');
                };
                
                audio.onerror = (error) => {
                    console.error('INTERACTIVE: Audio error:', error);
                    startNaturalTypewriter(element, question);
                };
                
                audio.load();
                
            } else {
                console.log('ðŸ–Šï¸ INTERACTIVE: No audio, using natural typewriter');
                startNaturalTypewriter(element, question);
            }
        }
        
        // Interruptible typewriter that can be stopped mid-sentence
        function startInterruptibleTypewriter(element, question, audioDuration) {
            let index = 0;
            const totalChars = question.length;
            const charDelay = (audioDuration * 1000) / totalChars;
            
            const typeNextChar = () => {
                if (index < question.length && isAISpeaking) {
                    element.innerHTML += question.charAt(index);
                    index++;
                    currentTypewriterInterval = setTimeout(typeNextChar, charDelay);
                } else if (!isAISpeaking) {
                    console.log('ðŸ›‘ INTERRUPTED: AI stopped speaking due to candidate interruption');
                }
            };
            
            typeNextChar();
        }
        
        // Setup interruption detection system
        function setupInterruptionDetection() {
            // Enable speech recognition during AI speech for interruption detection
            if (recognition && !isListening) {
                try {
                    isListening = true;
                    recognition.start();
                    console.log('ðŸŽ¤ INTERRUPTION DETECTION: Listening for candidate interruptions');
                } catch (e) {
                    console.log('Could not start interruption detection:', e);
                }
            }
        }
        
        // Handle candidate interruption
        function handleCandidateInterruption(spokenText) {
            if (isAISpeaking && spokenText.trim().length > 3) {
                console.log('ðŸ›‘ CANDIDATE INTERRUPTED: Stopping AI immediately');
                
                // Stop AI audio immediately
                if (currentAudioElement) {
                    currentAudioElement.pause();
                    currentAudioElement.currentTime = 0;
                }
                
                // Stop typewriter
                if (currentTypewriterInterval) {
                    clearInterval(currentTypewriterInterval);
                    currentTypewriterInterval = null;
                }
                
                // Clear AI speaking flag
                isAISpeaking = false;
                isProcessingResponse = false;
                
                // Show interruption message briefly
                const element = document.getElementById('conversationArea');
                element.innerHTML = '<div style="color: #ffa500; font-style: italic;">ðŸ’¬ You interrupted - I\'m listening...</div>';
                
                // Clear the interruption message after 1 second and show candidate response
                setTimeout(() => {
                    showCandidateResponse(spokenText);
                }, 1000);
                
                console.log('âœ… INTERRUPTION HANDLED: AI stopped, now processing candidate response');
                return true;
            }
            return false;
        }
        
        // Natural typewriter without audio sync
        function startNaturalTypewriter(element, question) {
            let index = 0;
            const streamText = () => {
                if (index < question.length) {
                    element.innerHTML += question.charAt(index);
                    index++;
                    setTimeout(streamText, 50); // Natural typing speed
                }
            };
            streamText();
        }
        
        // Show candidate response in same area after question disappears
        function showCandidateResponse(text) {
            const element = document.getElementById('conversationArea');
            // Clear the question first
            element.innerHTML = '';
            
            // Then stream the response
            let index = 0;
            const streamText = () => {
                if (index < text.length) {
                    element.innerHTML += text.charAt(index);
                    index++;
                    setTimeout(streamText, 20);
                }
            };
            streamText();
        }
        
        // Clear conversation area
        function clearConversation() {
            document.getElementById('conversationArea').innerHTML = '';
        }
        
        let collectedText = '';
        let speechTimeout = null;
        let lastSpeechTime = 0;
        let isProcessingResponse = false;
        
        // Initialize speech recognition with auto-start and auto-submit
        function initSpeech() {
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.lang = 'en-US';
                
                recognition.onstart = function() {
                    isListening = true;
                    collectedText = '';
                    document.getElementById('micBtn').classList.add('recording');
                    document.getElementById('micBtn').innerHTML = 'ðŸ”´';
                    console.log('Microphone started automatically');
                };
                
                recognition.onend = function() {
                    if (isListening && !isProcessingResponse) {
                        // Auto-restart to keep microphone always on
                        setTimeout(() => {
                            if (isListening && !isProcessingResponse) {
                                try {
                                    recognition.start();
                                } catch (e) {
                                    console.log('Recognition restart failed:', e);
                                }
                            }
                        }, 100);
                    }
                };
                
                recognition.onerror = function(event) {
                    console.log('Speech recognition error:', event.error);
                    if (event.error === 'no-speech' || event.error === 'audio-capture') {
                        // Restart on common errors
                        setTimeout(() => {
                            if (isListening && !isProcessingResponse) {
                                try {
                                    recognition.start();
                                } catch (e) {
                                    console.log('Recognition restart after error failed:', e);
                                }
                            }
                        }, 1000);
                    }
                };
                
                recognition.onresult = function(event) {
                    let interimTranscript = '';
                    let finalTranscript = '';
                    
                    for (let i = event.resultIndex; i < event.results.length; i++) {
                        if (event.results[i].isFinal) {
                            finalTranscript += event.results[i][0].transcript;
                        } else {
                            interimTranscript += event.results[i][0].transcript;
                        }
                    }
                    
                    const currentText = finalTranscript + interimTranscript;
                    
                    // INTERACTIVE CONVERSATION: Check for interruption during AI speech
                    if (isAISpeaking && currentText.trim().length > 0) {
                        // Check if this is a real interruption (not AI echo)
                        const aiPhrases = ['tell me about', 'can you describe', 'what are your', 'how do you', 'thank you for', 'that sounds great', 'excellent', 'interesting'];
                        const textLower = currentText.toLowerCase();
                        
                        // If it doesn't sound like AI echo, treat as interruption
                        if (!aiPhrases.some(phrase => textLower.includes(phrase))) {
                            if (handleCandidateInterruption(currentText)) {
                                // Interruption handled, collect this text for response
                                collectedText = currentText;
                                return;
                            }
                        } else {
                            console.log('ðŸ”‡ FILTERED: AI echo detected, ignoring');
                            return;
                        }
                    }
                    
                    // Normal processing when AI is not speaking
                    if (!isAISpeaking && !isProcessingResponse) {
                        // Collect all text
                        if (finalTranscript) {
                            collectedText += finalTranscript;
                            lastSpeechTime = Date.now();
                            
                            // Clear any existing timeout
                            if (speechTimeout) {
                                clearTimeout(speechTimeout);
                            }
                            
                            // Set timeout to auto-submit after 1 second of silence
                            speechTimeout = setTimeout(() => {
                                if (collectedText.trim() && !isProcessingResponse) {
                                    autoSubmitResponse();
                                }
                            }, 1000);
                        }
                        
                        // Show live text with interim results
                        const displayText = collectedText + interimTranscript;
                        if (displayText.trim()) {
                            document.getElementById('conversationArea').innerHTML = displayText;
                            
                            // Update last speech time for interim results too
                            if (interimTranscript.trim()) {
                                lastSpeechTime = Date.now();
                            }
                        }
                    }
                };
                
                // Start microphone automatically
                startMicrophone();
            }
        }
        
        // Auto-submit response when candidate stops speaking
        function autoSubmitResponse() {
            if (isProcessingResponse || !collectedText.trim()) return;
            
            console.log('Auto-submitting response after speech pause');
            isProcessingResponse = true;
            
            // Clear the timeout
            if (speechTimeout) {
                clearTimeout(speechTimeout);
                speechTimeout = null;
            }
            
            // Send the response
            const responseText = collectedText.trim();
            collectedText = ''; // Clear for next response
            
            sendResponse(responseText).finally(() => {
                // Reset processing flag immediately (no delay)
                isProcessingResponse = false;
            });
        }
        
        // Start microphone automatically
        function startMicrophone() {
            if (recognition && !isListening) {
                try {
                    isListening = true;
                    recognition.start();
                    console.log('Microphone started automatically for professional interview');
                } catch (e) {
                    console.log('Failed to start microphone:', e);
                }
            }
        }
        
        // Toggle microphone (only allows manual turn off, auto-restarts)
        function toggleMic() {
            if (!recognition) return;
            
            if (isListening) {
                // Only allow manual turn off, but warn user
                if (confirm('Are you sure you want to turn off the microphone? This is not recommended during an interview.')) {
                    isListening = false;
                    isProcessingResponse = true;
                    recognition.stop();
                    document.getElementById('micBtn').classList.remove('recording');
                    document.getElementById('micBtn').innerHTML = 'ðŸŽ¤';
                    
                    // Clear any pending timeouts
                    if (speechTimeout) {
                        clearTimeout(speechTimeout);
                        speechTimeout = null;
                    }
                    
                    // Send the collected text to server if any
                    if (collectedText.trim()) {
                        sendResponse(collectedText.trim());
                        collectedText = '';
                    }
                    
                    // Show warning message
                    showWarningMessage('Microphone turned off. Click the microphone button to turn it back on.');
                }
            } else {
                // Restart listening
                isListening = true;
                isProcessingResponse = false;
                collectedText = '';
                try {
                    recognition.start();
                    hideWarningMessage();
                } catch (e) {
                    console.log('Failed to restart microphone:', e);
                }
            }
        }
        
        // Show warning message
        function showWarningMessage(message) {
            const warningDiv = document.createElement('div');
            warningDiv.id = 'micWarning';
            warningDiv.className = 'mic-warning';
            warningDiv.innerHTML = `ðŸš¨ ${message}`;
            document.body.appendChild(warningDiv);
        }
        
        // Hide warning message
        function hideWarningMessage() {
            const warning = document.getElementById('micWarning');
            if (warning) {
                warning.remove();
            }
        }
        
        // Send response to server
        async function sendResponse(text) {
            try {
                console.log('Sending response:', text);
                
                const response = await fetch(window.location.href, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/x-www-form-urlencoded',
                        'X-CSRFToken': document.querySelector('[name=csrfmiddlewaretoken]').value,
                    },
                    body: new URLSearchParams({ text: text })
                });
                
                const data = await response.json();
                
                if (data.success) {
                    // FIXED: Show new question with audio sync
                    showCurrentQuestion(data.response, data.audio, data.audio_duration);
                    
                    // Update counter
                    questionCount = data.question_count || questionCount + 1;
                    document.getElementById('questionCount').textContent = questionCount + '/8';
                    
                    // INTERACTIVE: Enable interruption during AI speech
                    if (data.audio && data.audio.trim() !== '' && data.audio !== 'None') {
                        // Don't block speech recognition - enable interruption
                        isProcessingResponse = false; // Allow interruptions
                        console.log('ðŸ—£ï¸ INTERACTIVE: AI will speak - interruptions ENABLED');
                        
                        const audio = document.getElementById('aiAudio');
                        
                        // Set up natural conversation flow
                        audio.addEventListener('ended', () => {
                            isAISpeaking = false;
                            isProcessingResponse = false;
                            console.log('âœ… AI finished speaking naturally - ready for response');
                        }, { once: true });
                        
                        // Fallback to ensure we don't get stuck
                        setTimeout(() => {
                            if (isAISpeaking) {
                                isAISpeaking = false;
                                isProcessingResponse = false;
                                console.log('â° FALLBACK: Ensuring conversation continues');
                            }
                        }, 15000);
                        
                    } else {
                        // No audio, ready immediately
                        isProcessingResponse = false;
                        console.log('âœ… Ready for candidate response (no audio)');
                    }
                    
                    // Check if complete
                    if (data.is_final || questionCount >= 8) {
                        setTimeout(endInterview, 3000);
                    }
                }
            } catch (error) {
                console.error('Send error:', error);
                isProcessingResponse = false; // Reset on error
            }
        }
        
        // Timer
        function updateTimer() {
            const minutes = Math.floor(timeLeft / 60);
            const seconds = timeLeft % 60;
            document.getElementById('timer').textContent = 
                minutes + ':' + seconds.toString().padStart(2, '0');
            
            if (timeLeft <= 0) {
                endInterview();
                return;
            }
            timeLeft--;
        }
        
        // End interview
        function endInterview() {
            if (recognition && isListening) {
                isListening = false;
                recognition.stop();
            }
            alert('Interview completed! Redirecting to dashboard...');
            window.location.href = '{% url "jobseeker_dashboard" %}';
        }
        
        // Enhanced audio isolation to prevent feedback
        function setupAudioIsolation() {
            const aiAudio = document.getElementById('aiAudio');
            if (aiAudio) {
                // Lower volume to reduce feedback
                aiAudio.volume = 0.6;
                
                // Block speech recognition during AI speech
                aiAudio.addEventListener('play', function() {
                    isProcessingResponse = true;
                    console.log('ðŸ”‡ AI AUDIO PLAYING - Speech recognition BLOCKED');
                });
                
                aiAudio.addEventListener('ended', function() {
                    // Keep blocking for 2 more seconds after audio ends
                    setTimeout(() => {
                        isProcessingResponse = false;
                        console.log('ðŸ”Š AI AUDIO ENDED - Speech recognition UNBLOCKED');
                    }, 2000);
                });
                
                aiAudio.addEventListener('pause', function() {
                    setTimeout(() => {
                        isProcessingResponse = false;
                        console.log('â¸ï¸ AI AUDIO PAUSED - Speech recognition UNBLOCKED');
                    }, 1000);
                });
            }
        }
        
        // Initialize everything
        document.addEventListener('DOMContentLoaded', function() {
            initCamera();
            initSpeech();
            setupAudioIsolation(); // Use new audio isolation function
            setInterval(updateTimer, 1000);
            
            // Clear conversation area initially
            clearConversation();
            
            // FIXED: Show initial question with audio sync
            const initialQuestion = '{{ ai_question|default:"Hello! Welcome to your AI interview. Can you tell me about yourself?" }}';
            const initialAudio = '{{ audio_url|safe }}';
            const initialDuration = {{ audio_duration|default:"null" }};
            
            // Block speech recognition initially if there's audio
            if (initialAudio && initialAudio.trim() !== '' && initialAudio !== 'None') {
                isProcessingResponse = true;
                console.log('ðŸ”’ INITIAL BLOCK: AI will speak first');
            }
            
            // Show question with proper audio sync
            showCurrentQuestion(initialQuestion, initialAudio, initialDuration);
            
            // Show professional interview notice
            showProfessionalNotice();
        });
        
        // Show professional interview notice
        function showProfessionalNotice() {
            const notice = document.createElement('div');
            notice.className = 'professional-notice';
            notice.innerHTML = 'ðŸŽ¤ Professional Interview Mode: Microphone is ALWAYS ON';
            document.body.appendChild(notice);
            
            // Remove notice after 5 seconds
            setTimeout(() => {
                notice.style.animation = 'slideUp 0.5s ease-out forwards';
                setTimeout(() => notice.remove(), 500);
            }, 5000);
        }
        
        // Update audio level visualization
        function updateAudioLevelIndicator(level = 0) {
            const indicator = document.getElementById('audioLevelIndicator');
            if (!indicator) return;
            
            const bars = indicator.querySelectorAll('.audio-level-bar');
            const activeCount = Math.floor((level / 100) * bars.length);
            
            bars.forEach((bar, index) => {
                if (index < activeCount) {
                    bar.classList.add('active');
                } else {
                    bar.classList.remove('active');
                }
            });
        }
        
        // Handle speech result with enhanced UI and auto-submission
        function handleSpeechResult(event) {
            let interimTranscript = '';
            let finalTranscript = '';
            
            for (let i = event.resultIndex; i < event.results.length; i++) {
                if (event.results[i].isFinal) {
                    finalTranscript += event.results[i][0].transcript;
                } else {
                    interimTranscript += event.results[i][0].transcript;
                }
            }
            
            // Collect all text and handle auto-submission
            if (finalTranscript) {
                collectedText += finalTranscript;
                lastSpeechTime = Date.now();
                
                // Clear any existing timeout
                if (speechTimeout) {
                    clearTimeout(speechTimeout);
                }
                
                // Set timeout to auto-submit after 0.5 seconds of silence (faster response)
                speechTimeout = setTimeout(() => {
                    if (collectedText.trim() && !isProcessingResponse) {
                        autoSubmitResponse();
                    }
                }, 500);
            }
            
            // Show live text with enhanced styling
            const displayText = collectedText + interimTranscript;
            const conversationArea = document.getElementById('conversationArea');
            if (displayText.trim() && conversationArea) {
                conversationArea.innerHTML = displayText;
                conversationArea.className = 'conversation-text live-transcription';
                
                // Simulate audio level based on speech activity
                updateAudioLevelIndicator(interimTranscript ? 60 : 20);
                
                // Update last speech time for interim results too
                if (interimTranscript.trim()) {
                    lastSpeechTime = Date.now();
                }
            }
        }
        
        // Make handleSpeechResult globally available
        window.handleSpeechResult = handleSpeechResult;
    </script>
</body>
</html>